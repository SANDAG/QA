{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QA of Scheduled Developments in Forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### source data: demographic warehouse <br> preliminary forecast 2021 RTP (datasource id 30) & 2018 estimates (datasource id 27)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. check for sched dev that are built or partially built at the start of the forecast<br>&emsp; by finding MGRAs that have  both: <br> &emsp;&emsp; unit changes in the vintage 2018 estimates for yrs 2017 to 2018 & scheduled developments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### set up python environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up python environment\n",
    "import numpy as np\n",
    "import os \n",
    "import sys\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import xlsxwriter\n",
    "from matplotlib import pyplot as plt\n",
    "from pandas.plotting import table \n",
    "%matplotlib inline\n",
    "# connect to database\n",
    "db_connection_string = 'mssql+pyodbc://sql2014a8/ws?driver=SQL+Server+Native+Client+11.0'\n",
    "mssql_engine = create_engine(db_connection_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### get all MGRAs w sched dev AND unit increase 2017 to 2018 (source: estimates 2018, datasource 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: use isam.xpef23.parcel_du_xref_post2017 as crosswalk from parcel to mgra \n",
    "# to be consistent w demographic warehouse. DO NOT use urbansim.parcel\n",
    "# Use urbansim.scheduled_development_parcel to get site ids.  DO NOT use urbansim.parcel \n",
    "# since some parcels are missing sched dev site ids\n",
    "sql_query = '''\n",
    "WITH estimates2018_yr2018 AS (\n",
    "        SELECT mgra,sum(units) as estimates_units2018, geozone\n",
    "          FROM demographic_warehouse.fact.housing\n",
    "          JOIN demographic_warehouse.dim.mgra \n",
    "            ON mgra.mgra_id = housing.mgra_id\n",
    "         WHERE datasource_id = 27 AND geotype = 'region' AND yr_id = 2018 AND \n",
    "               mgra IN (\n",
    "                    SELECT DISTINCT mgra\n",
    "                      FROM urbansim.urbansim.scheduled_development_parcel sched_dev\n",
    "                      JOIN isam.xpef23.parcel_du_xref_post2017 xpef23\n",
    "                        ON sched_dev.parcel_id =  xpef23.parcel_id)  \n",
    "      GROUP BY yr_id, mgra, datasource_id, geozone),\n",
    "     estimates2018_yr2017 AS (\n",
    "        SELECT mgra,sum(units) as estimates_units2017\n",
    "          FROM demographic_warehouse.fact.housing\n",
    "          JOIN demographic_warehouse.dim.mgra \n",
    "            ON mgra.mgra_id = housing.mgra_id\n",
    "         WHERE datasource_id = 27 AND geotype = 'region' AND  yr_id = 2017 AND \n",
    "               mgra IN (\n",
    "                    SELECT DISTINCT mgra\n",
    "                      FROM urbansim.urbansim.scheduled_development_parcel sched_dev\n",
    "                      JOIN isam.xpef23.parcel_du_xref_post2017 xpef23\n",
    "                        ON sched_dev.parcel_id =  xpef23.parcel_id) \n",
    "      GROUP BY yr_id, mgra, datasource_id, geozone),\n",
    "     estimates2018_yr2016 AS (\n",
    "        SELECT mgra,sum(units) as estimates_units2016\n",
    "          FROM demographic_warehouse.fact.housing\n",
    "          JOIN demographic_warehouse.dim.mgra \n",
    "            ON mgra.mgra_id = housing.mgra_id\n",
    "         WHERE datasource_id = 27 AND geotype = 'region' AND  yr_id = 2016 AND \n",
    "               mgra IN (\n",
    "                    SELECT DISTINCT mgra\n",
    "                      FROM urbansim.urbansim.scheduled_development_parcel sched_dev\n",
    "                      JOIN isam.xpef23.parcel_du_xref_post2017 xpef23\n",
    "                        ON sched_dev.parcel_id =  xpef23.parcel_id) \n",
    "      GROUP BY yr_id, mgra, datasource_id, geozone)\n",
    "SELECT estimates2018_yr2018.mgra, estimates_units2016,estimates_units2017, estimates_units2018,\n",
    "       estimates_units2018-estimates_units2017 as estimates_unit_change_2017_to_2018\n",
    "  FROM estimates2018_yr2018\n",
    "  JOIN estimates2018_yr2017\n",
    "    ON estimates2018_yr2018.mgra = estimates2018_yr2017.mgra\n",
    "  JOIN estimates2018_yr2016\n",
    "    ON estimates2018_yr2018.mgra = estimates2018_yr2016.mgra\n",
    " WHERE estimates_units2018 > estimates_units2017\n",
    "'''\n",
    "mgras = pd.read_sql(sql_query, mssql_engine)\n",
    "mgras.sort_values(by=['estimates_unit_change_2017_to_2018'],ascending=False,inplace=True)\n",
    "mgras.reset_index(drop=True,inplace=True)\n",
    "# get list of the MGRAs as string for query\n",
    "mgras.mgra = mgras.mgra.astype('int64')\n",
    "mgralist = mgras['mgra'].values.tolist()\n",
    "mgrastr = ','.join(map(str, mgralist))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MGRAs w/ scheduled development and unit increase 2017 to 2018 (source: estimates 2018 datasource 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n\\nCount of MGRAs: (with sched dev & unit increase 2017 to 2018 based on estimates): ',len(mgralist))\n",
    "print('\\n\\nTotal unit increase for those MGRAs: '\\\n",
    "      ,mgras.estimates_unit_change_2017_to_2018.sum())\n",
    "print('\\nMgras are:',mgrastr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### get sched dev site ids for each MGRA (w unit change from 2017 to 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query = '''\n",
    "SELECT mgra,site_id \n",
    "FROM urbansim.urbansim.scheduled_development_parcel sched_dev\n",
    "JOIN isam.xpef23.parcel_du_xref_post2017 xpef23\n",
    "ON sched_dev.parcel_id =  xpef23.parcel_id\n",
    "WHERE mgra IN ({})'''.format(mgrastr) \n",
    "sites = pd.read_sql(sql_query, mssql_engine)\n",
    "sites.site_id = sites.site_id.astype('int64')\n",
    "sites.mgra = sites.mgra.astype('int64')\n",
    "\n",
    "sites_by_mgra = sites.groupby('mgra', as_index=False).agg(lambda x: ', '.join(set(x.astype(str))))\n",
    "mgra_site = pd.merge(mgras, sites_by_mgra, on='mgra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mgra_site.style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### for each of these MGRAs get the capacity from jur provided, sched dev, and adu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query = '''\n",
    "    SELECT  mgra,\n",
    "            sum([capacity_2]) as [jurisdiction provided capacity],\n",
    "            sum([capacity_3]) as [scheduled development capacity],\n",
    "            sum([capacity_ADU]) as [ADU capacity]\n",
    "       FROM urbansim.urbansim.vi_capacity\n",
    "       JOIN isam.xpef23.parcel_du_xref_post2017 \n",
    "         ON parcel_du_xref_post2017.parcel_id = vi_capacity.parcel_id\n",
    "      WHERE mgra IN ({})'''.format(mgrastr) + \" GROUP BY mgra\"\n",
    "all_capacity = pd.read_sql(sql_query, mssql_engine)\n",
    "all_capacity['total_capacity'] = all_capacity['jurisdiction provided capacity'] + \\\n",
    "all_capacity['scheduled development capacity'] + \\\n",
    "all_capacity['ADU capacity']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get unit change in forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unit change demographic warehouse\n",
    "sql_query = '''\n",
    "With dw2050 AS (\n",
    "SELECT mgra,sum([units]) as forecast_units2050,geozone\n",
    "  FROM [demographic_warehouse].[fact].[housing]\n",
    "   JOIN demographic_warehouse.dim.mgra on mgra.mgra_id = housing.mgra_id\n",
    "  WHERE datasource_id = 30 and geotype = 'region'  and yr_id = 2050 and mgra IN ({})'''.format(mgrastr) +\\\n",
    "'''\n",
    "  GROUP by yr_id,mgra,datasource_id,geozone),\n",
    "  dw2016 AS (\n",
    "  SELECT mgra,sum([units]) as forecast_units2016\n",
    "  FROM [demographic_warehouse].[fact].[housing]\n",
    "  JOIN demographic_warehouse.dim.mgra on mgra.mgra_id = housing.mgra_id\n",
    "  WHERE datasource_id = 30 and geotype = 'region' and  yr_id = 2016 and mgra IN ({})'''.format(mgrastr) +\\\n",
    "'''\n",
    "  GROUP by yr_id,mgra)\n",
    "  SELECT dw2050.mgra,forecast_units2016,forecast_units2050,forecast_units2050-forecast_units2016 as unit_change_forecast\n",
    "  FROM dw2050\n",
    "  JOIN dw2016\n",
    "  ON dw2016.mgra = dw2050.mgra\n",
    "'''\n",
    "demographic_warehouse_df = pd.read_sql(sql_query, mssql_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capacity_forecast = pd.merge(demographic_warehouse_df, all_capacity, on='mgra')\n",
    "capacity_forecast['capacity_minus_forecast'] = capacity_forecast['total_capacity'] - capacity_forecast['unit_change_forecast']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# capacity_forecast[['mgra','unit_change_forecast','total_capacity','capacity_minus_forecast']].style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.merge(capacity_forecast, mgra_site, on='mgra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = result.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['mgra','site_id','estimates_units2017','estimates_units2018','estimates_unit_change_2017_to_2018',\\\n",
    "        'forecast_units2016','forecast_units2050','unit_change_forecast',\\\n",
    "        'jurisdiction provided capacity','scheduled development capacity','ADU capacity','total_capacity',\\\n",
    "       'capacity_minus_forecast']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result.style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('sched_dev_forecast_QA.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# urbansim output run id 444 and mgras\n",
    "sql_query = '''\n",
    "SELECT run_id,mgra,sum([unit_change]) as unit_change,COALESCE(site_id,0) as site_id,\n",
    "    [year_simulation],[capacity_type]\n",
    "FROM [urbansim].[urbansim].[urbansim_lite_output] o\n",
    "JOIN isam.xpef23.parcel_du_xref_post2017 xpef23 \n",
    "    ON xpef23.parcel_id = o.parcel_id\n",
    "LEFT JOIN urbansim.urbansim.scheduled_development_parcel sched_dev\n",
    "    ON sched_dev.parcel_id = o.parcel_id\n",
    "WHERE run_id = 444 and \n",
    "mgra IN ({})'''.format(mgrastr) + '''\n",
    "GROUP BY year_simulation,capacity_type,mgra,run_id,site_id\n",
    "ORDER by mgra'''\n",
    "urbansim_out_df = pd.read_sql(sql_query, mssql_engine)\n",
    "urbansim_out_df.mgra = urbansim_out_df.mgra.astype('int64')\n",
    "urbansim_out_df.site_id = urbansim_out_df.site_id.astype('int64')\n",
    "#urbansim_out_df.site_id.replace(0, np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx =  pd.Series(range(2016,2051))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urbansim_out_df_sch = urbansim_out_df.loc[urbansim_out_df['capacity_type'] == 'sch'].copy()\n",
    "urbansim_out_df_jur = urbansim_out_df.loc[urbansim_out_df['capacity_type'] == 'jur'].copy()\n",
    "urbansim_out_df_adu = urbansim_out_df.loc[urbansim_out_df['capacity_type'] == 'adu'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urbansim_out_df_jur.site_id.replace(0, 'jur_provided_cap', inplace=True)\n",
    "urbansim_out_df_adu.site_id.replace(0, 'ADU', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgra_urb = pd.concat([urbansim_out_df_sch,urbansim_out_df_jur,urbansim_out_df_adu])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgra_urb = mgra_urb.sort_values(by=['mgra'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimates demographic warehouse id 27 units by year\n",
    "sql_query = '''\n",
    "    SELECT mgra,sum(units) as units,yr_id as year_simulation\n",
    "          FROM demographic_warehouse.fact.housing\n",
    "          JOIN demographic_warehouse.dim.mgra \n",
    "            ON mgra.mgra_id = housing.mgra_id\n",
    "         WHERE datasource_id = 27 AND geotype = 'region'  AND yr_id > 2016 AND\n",
    "               mgra IN ({})'''.format(mgrastr) + ''' \n",
    "      GROUP BY yr_id, mgra, datasource_id, geozone\n",
    "      ORDER BY mgra,yr_id'''\n",
    "estimates_df = pd.read_sql(sql_query, mssql_engine)\n",
    "# dw_df.mgra = dw_df.mgra.astype('int64')\n",
    "estimates_df.mgra = estimates_df.mgra.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimates_df['data_lagged'] = estimates_df.groupby(['mgra'])['units'].shift(1)\n",
    "estimates_df['unit_change'] = estimates_df['units'] - estimates_df['data_lagged']\n",
    "estimates_df.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimates_df.to_csv('estimates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forecast demographic warehouse id 30 units by year\n",
    "sql_query = '''\n",
    "SELECT datasource_id,yr_id as year_simulation,sum([units]) as units,mgra\n",
    "  FROM [demographic_warehouse].[fact].[housing]\n",
    "  JOIN demographic_warehouse.dim.mgra on mgra.mgra_id = housing.mgra_id\n",
    "  WHERE datasource_id = 30 and geotype = 'jurisdiction' AND\n",
    "  mgra IN ({})'''.format(mgrastr) + '''\n",
    "  GROUP by yr_id,datasource_id,mgra\n",
    "  ORDER by mgra,yr_id'''\n",
    "dw_df = pd.read_sql(sql_query, mssql_engine)\n",
    "dw_df.mgra = dw_df.mgra.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dw_df['data_lagged'] = dw_df.groupby(['mgra'])['units'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dw_df['unit_change'] = dw_df['units'] - dw_df['data_lagged']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dw_df.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dw_df.to_csv('forecast.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PLOT RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an new Excel file and add a worksheet.\n",
    "workbook = xlsxwriter.Workbook('images.xlsx')\n",
    "worksheet = workbook.add_worksheet()\n",
    "# Widen the first column to make the text clearer.\n",
    "worksheet.set_column('A:A', 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "counter = 2\n",
    "for i in mgra_urb.mgra.unique():\n",
    "    df = mgra_urb[mgra_urb['mgra']==i]\n",
    "    df2 = dw_df[dw_df['mgra']==i].copy()\n",
    "    df2.rename(columns={'mgra':'forecast for mgra'},inplace=True)\n",
    "    df3 = estimates_df[estimates_df['mgra']==i].copy()\n",
    "    df3.rename(columns={'mgra':'estimates for mgra'},inplace=True)\n",
    "    ylimmax = max(df2.unit_change.max(),df.unit_change.max(),df3.unit_change.max())\n",
    "    \n",
    "    df_pivot = df.pivot(index='year_simulation', columns='site_id', values='unit_change')\n",
    "    df_pivot = df_pivot.fillna(0)\n",
    "    df_pivot = df_pivot.reindex(idx, fill_value=0)\n",
    "    df2_pivot = df2.pivot(index='year_simulation', columns='forecast for mgra', values='unit_change')\n",
    "    df2_pivot = df2_pivot.fillna(0)\n",
    "    df2_pivot = df2_pivot.reindex(idx, fill_value=0)\n",
    "    df2_pivot.index.name = 'forecast for mgra'\n",
    "    \n",
    "    df3_pivot = df3.pivot(index='year_simulation', columns='estimates for mgra', values='unit_change')\n",
    "    df3_pivot = df3_pivot.fillna(0)\n",
    "    df3_pivot = df3_pivot.reindex(idx, fill_value=0)\n",
    "    df3_pivot.index.name = 'estimates for mgra'\n",
    "    \n",
    "    # plot table\n",
    "    x = result[result['mgra']==i]\n",
    "    imgdata = BytesIO()\n",
    "    y = x[['mgra','estimates_unit_change_2017_to_2018','jurisdiction provided capacity',\\\n",
    "       'scheduled development capacity','ADU capacity','total_capacity',\\\n",
    "       'unit_change_forecast']]\n",
    "    y.set_index('mgra',inplace=True)\n",
    "    yt = y.T\n",
    "    fig, ax = plt.subplots(figsize=(12, 2)) # set size frame\n",
    "    ax.xaxis.set_visible(False)  # hide the x axis\n",
    "    ax.yaxis.set_visible(False)  # hide the y axis\n",
    "    ax.set_frame_on(False)  # no visible frame, uncomment if size is ok\n",
    "    tabla = table(ax, yt, loc='upper right', colWidths=[0.17]*len(df.columns))  # where df is your data frame\n",
    "    tabla.auto_set_font_size(False) # Activate set fontsize manually\n",
    "    tabla.set_fontsize(12) # if ++fontsize is necessary ++colWidths\n",
    "    tabla.scale(1.2, 1.2) # change size table\n",
    "    fig.savefig(imgdata, format=\"png\")\n",
    "    placeholder = 'X' + str(counter)\n",
    "    imgdata.seek(0)\n",
    "    worksheet.insert_image(placeholder, \"\",{'image_data': imgdata})\n",
    "    plt.close(fig)\n",
    "    \n",
    "    #plt.figure()\n",
    "    ax = df_pivot.plot(title='Urbansim for MGRA ' + str(i),style='.-')\n",
    "    ax.set_ylim(0,ylimmax)\n",
    "    imgdata = BytesIO()\n",
    "    fig = ax.get_figure()\n",
    "    plt.ylabel('unit change')\n",
    "    plt.xlabel('urbansim year')\n",
    "    filename = 'sched_dev_mgra_' + str(i) + '_.png'\n",
    "    fig.savefig(imgdata, format=\"png\")\n",
    "    placeholder = 'L' + str(counter)\n",
    "    imgdata.seek(0)\n",
    "    worksheet.insert_image(placeholder, \"\",{'image_data': imgdata})\n",
    "    plt.close(fig)\n",
    "    \n",
    "    \n",
    "    #plt.figure()\n",
    "    ax = df2_pivot.plot(title='Demographic Warehouse for MGRA ' + str(i),style='.-',\\\n",
    "                       color='black')\n",
    "    ax.set_ylim(0,ylimmax)\n",
    "    imgdata = BytesIO()\n",
    "    fig = ax.get_figure()\n",
    "    plt.ylabel('unit change')\n",
    "    plt.xlabel('forecast increment')\n",
    "    filename = 'demographic_warehouse_' + str(i) + '_.png'\n",
    "    fig.savefig(imgdata, format=\"png\")\n",
    "    placeholder = 'V' + str(counter)\n",
    "    imgdata.seek(0)\n",
    "    worksheet.insert_image(placeholder, \"\",{'image_data': imgdata})\n",
    "    plt.close(fig)\n",
    "    \n",
    "    #plt.figure()\n",
    "    ax = df3_pivot.plot(title='Estimates for MGRA ' + str(i),style='.-',\\\n",
    "                        color='red')\n",
    "    ax.set_ylim(0,ylimmax)\n",
    "    imgdata = BytesIO()\n",
    "    fig = ax.get_figure()\n",
    "    plt.ylabel('unit change')\n",
    "    plt.xlabel('estimates 2017-2018')\n",
    "    filename = 'demographic_warehouse_' + str(i) + '_.png'\n",
    "    fig.savefig(imgdata, format=\"png\")\n",
    "    placeholder = 'B' + str(counter)\n",
    "    imgdata.seek(0)\n",
    "    worksheet.insert_image(placeholder, \"\",{'image_data': imgdata})\n",
    "    plt.close(fig)\n",
    "    \n",
    "    \n",
    "    # plt.savefig('table.png', transparent=True)\n",
    "    \n",
    "    counter = counter + 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
