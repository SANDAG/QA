{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyodbc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Builder Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data\n",
    "def import_mgra_based_data(path):\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    # I will be rolling up values using the mgra denorm file, so I can drop these columns\n",
    "    df = df.drop(['taz', 'LUZ'], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download sql_data\n",
    "def download_mgra_denorm_data(geo_level):\n",
    "    conn = pyodbc.connect('Driver={ODBC Driver 17 for SQL Server};'\n",
    "                    'Server=DDAMWSQL16.sandag.org;'\n",
    "                    'Database=estimates;'\n",
    "                    'Trusted_Connection=yes;')\n",
    "    \n",
    "    with open(rf'sql_queries\\mgra_denorm.sql', 'r') as sql_file:\n",
    "        sql_query = sql_file.read()\n",
    "    \n",
    "    return  pd.read_sql_query(sql_query, conn)[['mgra', geo_level]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge and Aggregate Data\n",
    "def merge_and_aggregate(mgra_input_file, mgra_denorm, geo_level):\n",
    "    df = pd.merge(mgra_denorm, mgra_input_file, how='left')\n",
    "\n",
    "    if geo_level != 'mgra':\n",
    "        df = df.drop('mgra', axis=1)\n",
    "\n",
    "    df = df.groupby(geo_level).sum()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hhs_adjustment(df):\n",
    "    \"\"\"Adjusts hhs values, returns the adjusted dataframe\"\"\"\n",
    "    df['hhs'] = df['hhp']/df['hh']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_data(output_folder_path, geo_level, version, df):\n",
    "    df.to_excel(output_folder_path + f\"\\mgra_based_input_{geo_level}_{version}.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mgra_denorm_table(mgra_denorm_path, geo_level, output_folder_path, version):\n",
    "    '''\n",
    "    In all paths add the 'r' command before the string\n",
    "    If you do not want the data outputted set output_folder_path to False'''\n",
    "    df_1 = import_mgra_based_data(path = mgra_denorm_path)\n",
    "\n",
    "    df_2 = download_mgra_denorm_data(geo_level=geo_level)\n",
    "\n",
    "    df_3 = merge_and_aggregate(mgra_input_file=df_1, mgra_denorm=df_2, geo_level=geo_level)\n",
    "\n",
    "    df_4 = hhs_adjustment(df_3)\n",
    "\n",
    "    if output_folder_path != False:\n",
    "        export_data(output_folder_path=output_folder_path, geo_level=geo_level, version=version, df=df_4)\n",
    "\n",
    "    return df_4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_levels = ['census_tract', 'cpa', 'jurisdiction', 'sra', 'luz', 'region']\n",
    "mgra_denorm_path = r'T:\\socioec\\Current_Projects\\SR15\\S0\\version3\\abm_csv\\mgra15_based_input_2022_01.csv'\n",
    "output_folder_path=r'C:\\Users\\cra\\San Diego Association of Governments\\SANDAG QA QC - Documents\\Projects\\2023\\2023-028 MGRA15 Input Table 2022\\2023-028-02\\Data'\n",
    "version='2023-028-02'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "census_tract is completed.\n",
      "cpa is completed.\n",
      "jurisdiction is completed.\n",
      "sra is completed.\n",
      "luz is completed.\n",
      "region is completed.\n"
     ]
    }
   ],
   "source": [
    "for geo_level in geo_levels:\n",
    "    create_mgra_denorm_table(mgra_denorm_path=mgra_denorm_path, \n",
    "                             geo_level=geo_level, \n",
    "                             output_folder_path=output_folder_path, \n",
    "                             version=version)\n",
    "    print(f\"{geo_level} is completed.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Internal Consistency Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_tract_data = create_mgra_denorm_table(mgra_denorm_path=mgra_denorm_path, \n",
    "                             geo_level='census_tract', \n",
    "                             output_folder_path=output_folder_path, \n",
    "                             version=version)\n",
    "cpa_data = create_mgra_denorm_table(mgra_denorm_path=mgra_denorm_path, \n",
    "                             geo_level='cpa', \n",
    "                             output_folder_path=output_folder_path, \n",
    "                             version=version)\n",
    "jurisdiction_data = create_mgra_denorm_table(mgra_denorm_path=mgra_denorm_path, \n",
    "                             geo_level='jurisdiction', \n",
    "                             output_folder_path=output_folder_path, \n",
    "                             version=version)\n",
    "sra_data = create_mgra_denorm_table(mgra_denorm_path=mgra_denorm_path, \n",
    "                             geo_level='sra', \n",
    "                             output_folder_path=output_folder_path, \n",
    "                             version=version)\n",
    "luz_data = create_mgra_denorm_table(mgra_denorm_path=mgra_denorm_path, \n",
    "                             geo_level='luz', \n",
    "                             output_folder_path=output_folder_path, \n",
    "                             version=version)\n",
    "region_data = create_mgra_denorm_table(mgra_denorm_path=mgra_denorm_path, \n",
    "                             geo_level='region', \n",
    "                             output_folder_path=output_folder_path, \n",
    "                             version=version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#region_data.sum()[10] = luz_data.sum()[10]\n",
    "\n",
    "close_indices = np.isclose(region_data.sum(), luz_data.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([10], dtype=int64),)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(~close_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def internal_consistency(df):\n",
    "    df['hh'] == df['i1'] + df['i2'] + df['i3'] + df['i4'] + df['i5'] + df['i6'] + df['i7'] + df['i8'] + df['i9'] + df['i10']\n",
    "    print('True HH')\n",
    "\n",
    "    df['hh'] == df['hh_sf'] + df['hh_mf'] \n",
    "    print('True hh')\n",
    "\n",
    "    df['pop'] == df['hhp'] + df['gq_civ'] + df['gq_mil']\n",
    "    print(\"true pop\")\n",
    "\n",
    "    df['emp_tot'] == df['emp_gov'] + df['emp_mil']\t+ df['emp_ag_min'] + df['emp_bus_svcs'] + df['emp_fin_res_mgm'] + df['emp_educ'] + df['emp_hlth'] +\tdf['emp_ret'] + df['emp_trn_wrh_con'] + df['emp_utl_mnf_whl'] + df['emp_ent'] + df['emp_accm']\t+ df['emp_food'] + df['emp_oth'] + df['emp_non_ws_wfh']\t+ df['emp_non_ws_oth']\n",
    "\n",
    "    print('true emp_total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True HH\n",
      "True hh\n",
      "true pop\n",
      "true emp_total\n"
     ]
    }
   ],
   "source": [
    "internal_consistency(df=sra_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hh'] = df['i1'] + df['i2'] + df['i3'] + df['i4'] + df['i5'] + df['i6'] + df['i7'] + df['i8'] + df['i9'] + df['i10']\n",
    "\n",
    "df['hh'] = df['hh_sf'] + df['hh_mf'] \n",
    "\n",
    "df['pop'] = df['hhp'] + df['gq_civ'] + df['gq_mil']\n",
    "\n",
    "df['emp_total'] = df['emp_gov'] + df['emp_mil']\t+ df['emp_ag_min'] + df['emp_bus_svcs'] + df['emp_fin_res_mgm'] + df['emp_educ'] + df['emp_hlth'] +\tdf['emp_ret'] + df['emp_trn_wrh_con'] + df['emp_utl_mnf_whl'] + df['emp_ent'] + df['emp_accm']\t+ df['emp_food'] + df['emp_oth'] + df['emp_non_ws_wfh']\t+ df['emp_non_ws_oth']\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
