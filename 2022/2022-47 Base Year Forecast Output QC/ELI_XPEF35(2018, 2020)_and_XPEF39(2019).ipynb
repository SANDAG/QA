{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2022-47 Base Year Forecast Output QC\n",
    "\n",
    "Test Plan: https://sandag.sharepoint.com/qaqc/_layouts/15/Doc.aspx?sourcedoc={f8b3d630-1290-445b-99a1-2fa9041ade92}&action=edit\n",
    "\n",
    "Documentation: https://sandag.sharepoint.com/:w:/r/qaqc/_layouts/15/Doc.aspx?sourcedoc=%7B3AF20D75-0A22-4B9C-9CC4-85B3EEC294E6%7D&file=MGRABased_input_ABM_2019_process_notes.docx "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_XPEF35_data():\n",
    "    \"\"\"\n",
    "    This function downloads XPEF35 data for the years 2018 and 2020\n",
    "\n",
    "    :returns:       Tuple with (2018 data, 2020 data)\n",
    "    \"\"\"\n",
    "    # Data is stored in this folder\n",
    "    data_folder_path = Path(r\"T:\\socioec\\Current_Projects\\XPEF35\\abm_csv\\New_mgra_based_input\")\n",
    "    \n",
    "    # Define the files here\n",
    "    files = [\"mgra13_based_input\" + year + \"_02.csv\" for year in [\"2018\", \"2020\"]]\n",
    "\n",
    "    # Download the data from each file and load into a dataframe\n",
    "    dfs = []\n",
    "    for file in files:\n",
    "        dfs.append(pd.read_csv(data_folder_path / file))\n",
    "\n",
    "    return dfs\n",
    "\n",
    "def download_XPEF39_data():\n",
    "    \"\"\"\n",
    "    This function downloads XPEF39 data for the year 2019\n",
    "\n",
    "    :returns:       df with 2019 data\n",
    "    \"\"\"\n",
    "    # Data is stored in this folder\n",
    "    data_folder_path = Path(r\"T:\\socioec\\Current_Projects\\XPEF39\\abm_csv\")\n",
    "    \n",
    "    # Define the files here\n",
    "    files = [\"mgra13_based_input2019_01.csv\"]\n",
    "\n",
    "    # Download the data from each file and load into a dataframe\n",
    "    dfs = []\n",
    "    for file in files:\n",
    "        dfs.append(pd.read_csv(data_folder_path / file))\n",
    "\n",
    "    return dfs[0]\n",
    "\n",
    "# Get data and put the dfs into named containers\n",
    "xpef35_2018, xpef35_2020 = download_XPEF35_data()\n",
    "xpef39_2019 = download_XPEF39_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the most part, region wide value for each variable can be computed using a simple sum. \n",
    "# However, for some variables, such as density varialbes or other variables, more advanced\n",
    "# calcuations must be done. \n",
    "\n",
    "# Here, I define which columns to drop as their data is meaningless in regional context\n",
    "# The items in this list which are commented out are variables which exist in ABM wiki but for\n",
    "# whatever reason do not exist in the downloaded files\n",
    "drop = [\n",
    "    \"pseudomsa\", # MSA does not matter when data is collected for the entire region\n",
    "    \"parkarea\", # Cross MGRA value, no meaning in region wide context\n",
    "    # \"luzid\", # ABM wiki has no description...\n",
    "    \"truckregiontype\", # ABM wiki has no description...\n",
    "    \"district27\", # ABM wiki has no description...\n",
    "    \"milestocoast\", # Obviously meaningless\n",
    "    # \"MicroAccessTime\", # Micro-mobility access time (mins) is too MGRA specific to aggregate\n",
    "    \"mgra\", # Ignore for simplicity\n",
    "    \"taz\", # Ignore for simplicity\n",
    "    \"zip09\", # Ignore for simplicity\n",
    "    # \"remoteAVParking\", # Ignore for simplicity\n",
    "]\n",
    "\n",
    "# Here, I define additional columns that need to be computed\n",
    "# The t_ prefix is used as a flag to delete these after processing\n",
    "additional_columns = {\n",
    "    # The number of the different kinds of parking stalls\n",
    "    \"t_num_hourly_stalls\": [\"sum\", \"hstallsoth\", \"hstallssam\"],\n",
    "    \"t_num_daily_stalls\": [\"sum\", \"dstallsoth\", \"dstallssam\"],\n",
    "    \"t_num_monthly_stalls\": [\"sum\", \"mstallsoth\", \"mstallssam\"],\n",
    "\n",
    "    # Dummy variables used to (at some point) compute average parking rates\n",
    "    \"t_hourly_stalls_total_cost\": [\"product\", \"t_num_hourly_stalls\", \"hparkcost\"],\n",
    "    \"t_daily_stalls_total_cost\": [\"product\", \"t_num_daily_stalls\", \"dparkcost\"],\n",
    "    \"t_monthly_stalls_total_cost\": [\"product\", \"t_num_monthly_stalls\", \"mparkcost\"],\n",
    "\n",
    "    # Get the total group quarter population\n",
    "    \"gq_total\": [\"sum\", \"gq_civ\", \"gq_mil\"],\n",
    "}\n",
    "\n",
    "# Here, I define which columns require special treatment\n",
    "complex_calculations = {\n",
    "    # # Collect all the different mgra numbers in the region\n",
    "    # \"mgra\": [\"collect\"],\n",
    "\n",
    "    # # Collect all the different taz numbers in the region\n",
    "    # \"taz\": [\"collect\"],\n",
    "\n",
    "    # Calculate household size by dividing total population by number of households\n",
    "    \"hhs\": [\"divide\", \"pop\", \"hh\"],\n",
    "\n",
    "    # Calculate aveage cost of parking for one hour in [hourly/daily/montly] stalls by dividing the\n",
    "    # total cost of all [hourly/daily/montly] stalls by the number of [hourly/daily/montly] stalls\n",
    "    \"hparkcost\": [\"divide\", \"t_hourly_stalls_total_cost\", \"t_num_hourly_stalls\"],\n",
    "    \"dparkcost\": [\"divide\", \"t_daily_stalls_total_cost\", \"t_num_daily_stalls\"],\n",
    "    \"mparkcost\": [\"divide\", \"t_monthly_stalls_total_cost\", \"t_num_monthly_stalls\"],\n",
    "\n",
    "    # # Collect all the different zip codes in the region\n",
    "    # \"zip09\": [\"collect\"],\n",
    "\n",
    "    # # Count the number of MGRAs that have remote AV parking\n",
    "    # \"remoteAVParking\": [\"count\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First make copies of the data so we don't have to keep accessing the T drive\n",
    "collated_2018 = xpef35_2018.copy(deep=True)\n",
    "collated_2019 = xpef39_2019.copy(deep=True)\n",
    "collated_2020 = xpef35_2020.copy(deep=True)\n",
    "\n",
    "# Drop the columns not needed\n",
    "collated_2018 = collated_2018.drop(drop, axis=1)\n",
    "collated_2019 = collated_2019.drop(drop, axis=1)\n",
    "collated_2020 = collated_2020.drop(drop, axis=1)\n",
    "\n",
    "# Do the add on the additional columns requested\n",
    "for new_col_name, computation in additional_columns.items():\n",
    "    if(computation[0] == \"sum\"):\n",
    "        collated_2018[new_col_name] = collated_2018[computation[1]] + collated_2018[computation[2]]\n",
    "        collated_2019[new_col_name] = collated_2019[computation[1]] + collated_2019[computation[2]]\n",
    "        collated_2020[new_col_name] = collated_2020[computation[1]] + collated_2020[computation[2]]\n",
    "    elif(computation[0] == \"product\"):\n",
    "        collated_2018[new_col_name] = collated_2018[computation[1]] * collated_2018[computation[2]]\n",
    "        collated_2019[new_col_name] = collated_2019[computation[1]] * collated_2019[computation[2]]\n",
    "        collated_2020[new_col_name] = collated_2020[computation[1]] * collated_2020[computation[2]]\n",
    "\n",
    "# Do the complex calculations\n",
    "# First just take the simple sum\n",
    "collated_2018 = collated_2018.sum()\n",
    "collated_2019 = collated_2019.sum()\n",
    "collated_2020 = collated_2020.sum()\n",
    "\n",
    "# Overwrite certain summed variables with the correct calculation\n",
    "for incorrect_col, correction in complex_calculations.items():\n",
    "    if(correction[0] == \"divide\"):\n",
    "        collated_2018[incorrect_col] = collated_2018[correction[1]] / collated_2018[correction[2]]\n",
    "        collated_2019[incorrect_col] = collated_2019[correction[1]] / collated_2019[correction[2]]\n",
    "        collated_2020[incorrect_col] = collated_2020[correction[1]] / collated_2020[correction[2]]\n",
    "\n",
    "# Remove temp columns (prefix of t_):\n",
    "collated_2018 = collated_2018.drop([x for x in additional_columns.keys() if \"t_\" in x])\n",
    "collated_2019 = collated_2019.drop([x for x in additional_columns.keys() if \"t_\" in x])\n",
    "collated_2020 = collated_2020.drop([x for x in additional_columns.keys() if \"t_\" in x])\n",
    "\n",
    "# Ensure we don't lose year values\n",
    "collated_2018[\"year\"] = 2018\n",
    "collated_2019[\"year\"] = 2019\n",
    "collated_2020[\"year\"] = 2020\n",
    "\n",
    "# Combine the collated files together\n",
    "regionwide = pd.DataFrame([collated_2018, collated_2019, collated_2020])\n",
    "\n",
    "# # Add a new row containing the difference in values\n",
    "# regionwide.loc[len(regionwide.index)] = regionwide.loc[1] - regionwide.loc[0]\n",
    "\n",
    "# Move the year column as the first column\n",
    "column_order = regionwide.columns.tolist()[-1:] + regionwide.columns.tolist()[:-1]\n",
    "regionwide = regionwide[column_order]\n",
    "\n",
    "# # Transpose and set year as column\n",
    "# regionwide = regionwide.transpose()\n",
    "# regionwide.columns = regionwide.iloc[0]\n",
    "# regionwide = regionwide.drop(regionwide.index[0])\n",
    "\n",
    "# # Other formatting things\n",
    "# regionwide.index.name = \"variable\"\n",
    "# regionwide.columns = [2018, 2020, \"difference\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A requirement added after the above was coded is to only select the variables we want to look at\n",
    "# and to do some additional diffs\n",
    "\n",
    "# The variables we want are the following:\n",
    "variables = [\n",
    "    # Of course we need to keep track of the year\n",
    "    \"year\",\n",
    "\n",
    "    # Population variables\n",
    "    \"pop\", \"hhp\", \"gq_total\",\n",
    "\n",
    "    # Housing variables\n",
    "    \"hs\", \"hh\", \"hhs\", \n",
    "    # \"vacant\", \"vacancy_rate\", These variables are not present in mgra files\n",
    "\n",
    "    # Employment variables, anything that starts with \"emp_\"\n",
    "    *[x for x in list(regionwide.columns) if \"emp_\" in x],\n",
    "\n",
    "    # School Enrollment variables, anything that has \"enroll\"\n",
    "    *[x for x in list(regionwide.columns) if \"enroll\" in x], \"adultschenrl\",\n",
    "\n",
    "    # Income variables\n",
    "    # None are present in mgra files\n",
    "\n",
    "    # Ethnicity by Category variables\n",
    "    # None are present in mgra files\n",
    "\n",
    "    # Age variables\n",
    "    # None are present in mgra files\n",
    "\n",
    "    # Hotel variables\n",
    "    *[x for x in list(regionwide.columns) if \"room\" in x],\n",
    "]\n",
    "regionwide = regionwide[variables]\n",
    "\n",
    "# Transpose and set year as column\n",
    "regionwide = regionwide.transpose()\n",
    "regionwide.columns = regionwide.iloc[0]\n",
    "regionwide = regionwide.drop(regionwide.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute numeric and percentage differences between all of the year combos\n",
    "\n",
    "# 2018 --> 2019\n",
    "regionwide[\"2018 --> 2019 numeric diff\"] = regionwide[2019] - regionwide[2018]\n",
    "regionwide[\"2018 --> 2019 percent diff\"] = 100 * (regionwide[2019] - regionwide[2018]) / regionwide[2018]\n",
    "\n",
    "# 2018 --> 2020\n",
    "regionwide[\"2018 --> 2020 numeric diff\"] = regionwide[2020] - regionwide[2018]\n",
    "regionwide[\"2018 --> 2020 percent diff\"] = 100 * (regionwide[2020] - regionwide[2018]) / regionwide[2018]\n",
    "\n",
    "# 2019 --> 2020\n",
    "regionwide[\"2019 --> 2020 numeric diff\"] = regionwide[2020] - regionwide[2019]\n",
    "regionwide[\"2019 --> 2020 percent diff\"] = 100 * (regionwide[2020] - regionwide[2019]) / regionwide[2019]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to csv file locally, will move the file manually to sharepoint later\n",
    "user = \"eli\"\n",
    "temp_folder = Path(r\"C:\\Users\\eli\\Documents\")\n",
    "filename = \"Regionwide_Comparison_XPEF35(2018_and_2020)_XPEF39(2019).csv\"\n",
    "regionwide.to_csv(temp_folder / filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('SANDAG')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "41c20cbfa603768ded13150453b5681e701a59febb16590ec3ab380b595ec114"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
