{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2022-53 ODP Data Surfer Extract QC (Estimates)\n",
    "\n",
    "Test Plan: https://sandag.sharepoint.com/qaqc/_layouts/15/Doc.aspx?sourcedoc={6411f490-19d0-49bd-9bf0-ab52890d61f9}&action=edit&wd=target%28Untitled%20Section.one%7C19ee188a-2490-42fc-97e2-ab6875fa748e%2FTest%20Plan%7C3e4ff64a-bad9-46e4-9a24-6dc76f5d34bf%2F%29\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlalchemy as sql\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "ddam = sql.create_engine('mssql+pymssql://DDAMWSQL16')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_raw_data(user, files):\n",
    "    \"\"\"\n",
    "    Download the six raw data files. Note that copies of these files were put into SharePoint.\n",
    "\n",
    "    :param user:    The user downloading the data from SharePoint. This is mostly here so that it\n",
    "                    is easy for anyone to run the code\n",
    "    :param files:   A list of the files to download\n",
    "    :returns:       Tuple containing dataframes representing the list of files in the order they\n",
    "                    appear\n",
    "    \"\"\"\n",
    "    # The folder where raw data is stored\n",
    "    base_url = Path(f\"C:/Users/{user}/San Diego Association of Governments/SANDAG QA QC - Documents/Projects/2022/2022-53 ODP Data Surfer Extract QC/ETL Data/Estimates/\")\n",
    "\n",
    "    # Get the six raw data files\n",
    "    raw_data = []\n",
    "    for file in files:\n",
    "        raw_data.append(pd.read_csv(base_url / file))\n",
    "\n",
    "    # Return the four raw data files in tuple format\n",
    "    return tuple(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_SQL_data(connection):\n",
    "    \"\"\"\n",
    "    Download the relevant (pre-transformed) tables from SQL\n",
    "\n",
    "    :param connection:  sqlalchemy connection to DDAMWSQL16\n",
    "    :returns:           Tuple containing dataframes representing the list of files in the order they\n",
    "                        appear, even though the file list is not input here\n",
    "    \"\"\"\n",
    "    # The tables are rather small, so there is no issue in just downloading all tables and holding\n",
    "    # them in memory\n",
    "    age_college = pd.read_sql_query(\"\"\"\n",
    "        SELECT geozone as 'college', yr_id, age_group.name, SUM(population) as population \n",
    "        FROM [demographic_warehouse].[fact].[age] as tbl\n",
    "        INNER JOIN [demographic_warehouse].[dim].[mgra] AS mgra ON \n",
    "            mgra.mgra_id = tbl.mgra_id\n",
    "        INNER JOIN [demographic_warehouse].[dim].[age_group] ON \n",
    "            age_group.age_group_id = tbl.age_group_id\n",
    "        WHERE \n",
    "            tbl.datasource_id = 40 AND \n",
    "            mgra.geotype = 'college'\n",
    "        GROUP BY mgra.geozone, yr_id, tbl.age_group_id, age_group.name\n",
    "        ORDER BY mgra.geozone, yr_id, tbl.age_group_id\n",
    "        \"\"\", con=connection)\n",
    "\n",
    "    age_sex_ethnicity_sd_council = pd.read_sql_query(\"\"\"\n",
    "    SELECT \n",
    "        geozone as 'sdcouncil', \n",
    "        yr_id, \n",
    "        age_group.name as age_group, \n",
    "        sex.sex as sex, \n",
    "        ethnicity.long_name as ethnicity, \n",
    "        SUM(population) as population \n",
    "    FROM [demographic_warehouse].[fact].[age_sex_ethnicity] as tbl\n",
    "    INNER JOIN [demographic_warehouse].[dim].[mgra] AS mgra ON \n",
    "        mgra.mgra_id = tbl.mgra_id\n",
    "    INNER JOIN [demographic_warehouse].[dim].[age_group] ON \n",
    "        age_group.age_group_id = tbl.age_group_id\n",
    "    INNER JOIN [demographic_warehouse].[dim].[sex] ON \n",
    "        sex.sex_id = tbl.sex_id\n",
    "    INNER JOIN [demographic_warehouse].[dim].[ethnicity] ON \n",
    "        ethnicity.ethnicity_id = tbl.ethnicity_id\n",
    "    WHERE \n",
    "        tbl.datasource_id = 40 AND \n",
    "        mgra.geotype = 'sdcouncil'\n",
    "    GROUP BY \n",
    "        mgra.geozone, \n",
    "        yr_id, \n",
    "        tbl.age_group_id, \n",
    "        tbl.sex_id, \n",
    "        tbl.ethnicity_id, \n",
    "        age_group.name, \n",
    "        sex.sex, \n",
    "        ethnicity.long_name\n",
    "    ORDER BY mgra.geozone, yr_id, tbl.age_group_id, tbl.sex_id, tbl.ethnicity_id\n",
    "    \"\"\", con=connection)\n",
    "\n",
    "    age_sex_ethnicity_zip = pd.read_sql_query(\"\"\"\n",
    "    SELECT \n",
    "        geozone as 'zip', \n",
    "        yr_id, \n",
    "        age_group.name as age_group, \n",
    "        sex.sex as sex, \n",
    "        ethnicity.long_name as ethnicity, \n",
    "        SUM(population) as population \n",
    "    FROM [demographic_warehouse].[fact].[age_sex_ethnicity] as tbl\n",
    "    INNER JOIN [demographic_warehouse].[dim].[mgra] AS mgra ON \n",
    "        mgra.mgra_id = tbl.mgra_id\n",
    "    INNER JOIN [demographic_warehouse].[dim].[age_group] ON \n",
    "        age_group.age_group_id = tbl.age_group_id\n",
    "    INNER JOIN [demographic_warehouse].[dim].[sex] ON \n",
    "        sex.sex_id = tbl.sex_id\n",
    "    INNER JOIN [demographic_warehouse].[dim].[ethnicity] ON \n",
    "        ethnicity.ethnicity_id = tbl.ethnicity_id\n",
    "    WHERE \n",
    "        tbl.datasource_id = 40 AND \n",
    "        mgra.geotype = 'zip'\n",
    "    GROUP BY \n",
    "        mgra.geozone, \n",
    "        yr_id, \n",
    "        tbl.age_group_id, \n",
    "        tbl.sex_id, \n",
    "        tbl.ethnicity_id, \n",
    "        age_group.name, \n",
    "        sex.sex, \n",
    "        ethnicity.long_name\n",
    "    ORDER BY mgra.geozone, yr_id, tbl.age_group_id, tbl.sex_id, tbl.ethnicity_id\n",
    "    \"\"\", con=connection)\n",
    "\n",
    "    housing_sra = pd.read_sql_query(\"\"\"\n",
    "    SELECT \n",
    "        geozone as 'sra', \n",
    "        yr_id, \n",
    "        structure_type.long_name, \n",
    "        SUM(units) as units, \n",
    "        SUM(unoccupiable) as unoccupiable, \n",
    "        SUM(occupied) as occupied, \n",
    "        SUM(vacancy) as vacancy\n",
    "    FROM [demographic_warehouse].[fact].[housing] as tbl\n",
    "    INNER JOIN [demographic_warehouse].[dim].[mgra] AS mgra ON \n",
    "        mgra.mgra_id = tbl.mgra_id\n",
    "    INNER JOIN [demographic_warehouse].[dim].[structure_type] ON \n",
    "        structure_type.structure_type_id = tbl.structure_type_id\n",
    "    WHERE \n",
    "        tbl.datasource_id = 40 AND \n",
    "        mgra.geotype = 'sra'\n",
    "    GROUP BY mgra.geozone, yr_id, tbl.structure_type_id, structure_type.long_name\n",
    "    ORDER BY mgra.geozone, yr_id, tbl.structure_type_id\n",
    "    \"\"\", con=connection)\n",
    "\n",
    "    population_sdcouncil = pd.read_sql_query(\"\"\"\n",
    "    SELECT geozone as 'sdcouncil', yr_id, housing_type.long_name, SUM(population) as population\n",
    "    FROM [demographic_warehouse].[fact].[population] as tbl\n",
    "    INNER JOIN [demographic_warehouse].[dim].[mgra] AS mgra ON \n",
    "        mgra.mgra_id = tbl.mgra_id\n",
    "    INNER JOIN [demographic_warehouse].[dim].[housing_type] ON \n",
    "        housing_type.housing_type_id = tbl.housing_type_id\n",
    "    WHERE \n",
    "        tbl.datasource_id = 40 AND \n",
    "        mgra.geotype = 'sdcouncil'\n",
    "    GROUP BY mgra.geozone, yr_id, tbl.housing_type_id, housing_type.long_name\n",
    "    ORDER BY mgra.geozone, yr_id, tbl.housing_type_id\n",
    "    \"\"\", con=connection)\n",
    "\n",
    "    sex_sdcouncil = pd.read_sql_query(\"\"\"\n",
    "    SELECT geozone as 'sdcouncil', yr_id, sex.sex, SUM(population) as population\n",
    "    FROM [demographic_warehouse].[fact].[sex] as tbl\n",
    "    INNER JOIN [demographic_warehouse].[dim].[mgra] AS mgra ON \n",
    "        mgra.mgra_id = tbl.mgra_id\n",
    "    INNER JOIN [demographic_warehouse].[dim].[sex] ON \n",
    "        sex.sex_id = tbl.sex_id\n",
    "    WHERE \n",
    "        tbl.datasource_id = 40 AND \n",
    "        mgra.geotype = 'sdcouncil'\n",
    "    GROUP BY mgra.geozone, yr_id, tbl.sex_id, sex.sex\n",
    "    ORDER BY mgra.geozone, yr_id, tbl.sex_id\n",
    "    \"\"\", con=connection)\n",
    "\n",
    "    # Return the SQL tables\n",
    "    return (age_college, age_sex_ethnicity_sd_council, age_sex_ethnicity_zip, housing_sra,\n",
    "        population_sdcouncil, sex_sdcouncil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The file names for the raw csv data\n",
    "RAW_FILES = [\n",
    "    Path(\"est_ds40_fact_age_college.csv\"),\n",
    "    Path(\"est_ds40_fact_age_sex_ethnicity_sdcouncil.csv\"),\n",
    "    Path(\"est_ds40_fact_age_sex_ethnicity_zip.csv\"),\n",
    "    Path(\"est_ds40_fact_housing_sra.csv\"),\n",
    "    Path(\"est_ds40_fact_population_sdcouncil.csv\"),\n",
    "    Path(\"est_ds40_fact_sex_sdcouncil.csv\"),\n",
    "]\n",
    "\n",
    "# Download both csv and sql data\n",
    "csv = download_raw_data(\"eli\", RAW_FILES)\n",
    "sql = download_SQL_data(ddam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Tests\n",
    "1. Check Shape\n",
    "2. Check values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(name, csv_df, sql_df, sum_cols):\n",
    "    \"\"\"\n",
    "    Run the tests (see test plan at the top of the notebook)\n",
    "\n",
    "    :param name:        The name of the file \n",
    "    :param csv_df:      The data as it appears in staging\n",
    "    :param sql_df:      The data as it appears in SQL\n",
    "    :param sum_cols:    The column(s) in list form for which to sum over to check total values\n",
    "    :returns:           None, but prints out test results\n",
    "    \"\"\"\n",
    "    # Print the file we are testing\n",
    "    print(\"Tests for \\\"\" + str(name) + \"\\\"\")\n",
    "\n",
    "    # Check shape\n",
    "    test_1_shape = (csv_df.shape == sql_df.shape)\n",
    "    print(f\"{'Shape test:' : <24}\", test_1_shape)\n",
    "    if(not test_1_shape):\n",
    "        print(f\"{'': <4}\", f\"{'csv shape:': <12}\", csv_df.shape)\n",
    "        print(f\"{'': <4}\", f\"{'sql shape:': <12}\", sql_df.shape)\n",
    "\n",
    "    # Check columns\n",
    "    test_1_col_names = (csv_df.columns == sql_df.columns)\n",
    "    print(f\"{'Column names test:' : <24}\", test_1_col_names)\n",
    "    if(not (test_1_col_names.sum() == len(test_1_col_names))):\n",
    "        print(f\"{'': <4}\", f\"{'csv columns:': <12}\", csv_df.columns)\n",
    "        print(f\"{'': <4}\", f\"{'sql columns:': <12}\", sql_df.columns)\n",
    "\n",
    "    # Check values\n",
    "    for sum_col in sum_cols:\n",
    "        test_2_sum = (csv_df[sum_col].sum() == sql_df[sum_col].sum())\n",
    "        print(f\"{sum_col + ' sum test:' : <24}\", test_2_sum)\n",
    "        if(not test_2_sum):\n",
    "            print(f\"{'': <4}\", f\"{'csv sum:': <12}\", csv_df[sum_col].sum())\n",
    "            print(f\"{'': <4}\", f\"{'sql sum:': <12}\", sql_df[sum_col].sum())\n",
    "\n",
    "    # New line at the end to space out the tests of different files\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests for \"est_ds40_fact_age_college.csv\"\n",
      "Shape test:              True\n",
      "Column names test:       [ True  True  True  True]\n",
      "population sum test:     True\n",
      "\n",
      "Tests for \"est_ds40_fact_age_sex_ethnicity_sdcouncil.csv\"\n",
      "Shape test:              True\n",
      "Column names test:       [ True  True  True  True  True  True]\n",
      "population sum test:     True\n",
      "\n",
      "Tests for \"est_ds40_fact_age_sex_ethnicity_zip.csv\"\n",
      "Shape test:              True\n",
      "Column names test:       [ True  True  True  True  True  True]\n",
      "population sum test:     True\n",
      "\n",
      "Tests for \"est_ds40_fact_housing_sra.csv\"\n",
      "Shape test:              True\n",
      "Column names test:       [ True  True  True  True  True  True  True]\n",
      "units sum test:          True\n",
      "unoccupiable sum test:   True\n",
      "occupied sum test:       True\n",
      "vacancy sum test:        True\n",
      "\n",
      "Tests for \"est_ds40_fact_population_sdcouncil.csv\"\n",
      "Shape test:              True\n",
      "Column names test:       [ True  True  True  True]\n",
      "population sum test:     True\n",
      "\n",
      "Tests for \"est_ds40_fact_sex_sdcouncil.csv\"\n",
      "Shape test:              True\n",
      "Column names test:       [ True  True  True  True]\n",
      "population sum test:     True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The columns within each file (in the order they appear) to sum over\n",
    "SUM_COL = [\n",
    "    [\"population\"],\n",
    "    [\"population\"],\n",
    "    [\"population\"],\n",
    "    [\"units\", \"unoccupiable\", \"occupied\", \"vacancy\"],\n",
    "    [\"population\"], \n",
    "    [\"population\"]\n",
    "]\n",
    "\n",
    "# Run the tests on all the files\n",
    "for i in range(0, len(RAW_FILES)):\n",
    "    test(RAW_FILES[i], csv[i], sql[i], SUM_COL[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('SANDAG')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "41c20cbfa603768ded13150453b5681e701a59febb16590ec3ab380b595ec114"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
