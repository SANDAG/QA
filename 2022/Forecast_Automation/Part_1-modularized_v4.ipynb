{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: The concat_dfs and create_diff functions are not-optimal for MGRA series 14, as they are designed for the anticipated MGRA series 15+. Therefore, we have created temp versions of these functions to use for MGRA series 14. When the series 15 gets released, these functions will need to be manually switched in the `GUI Implementation` section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#Libraries \n",
    "import os\n",
    "import pyodbc\n",
    "import glob\n",
    "import copy\n",
    "import PySimpleGUI as sg\n",
    "import traceback\n",
    "import xlsxwriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MGRA Level Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate both DS dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_dfs(comparison_first_ID_processed_data, comparison_second_ID_processed_data):\n",
    "    \"\"\"\n",
    "    Merges two mgra-level dataframes (generated by download_DS_data function) horizontally.\n",
    "    Returns a comparison table grouped by mgra and year.\n",
    "    \"\"\"\n",
    "    # Added geozone to merge keys to account for mgra's in multiple jurisdictions (or other geographical levels)\n",
    "    first_second_ID_comparison = comparison_first_ID_processed_data.merge(\n",
    "        comparison_second_ID_processed_data,\n",
    "        how='outer',\n",
    "        left_on=[f'mgra_{first_ID}',\n",
    "                 f'year_{first_ID}',\n",
    "                 f'geozone_{first_ID}'],\n",
    "        right_on=[f'mgra_{second_ID}',\n",
    "                 f'year_{second_ID}',\n",
    "                 f'geozone_{second_ID}'])\n",
    "    \n",
    "    # Clean green combined\n",
    "    first_second_ID_comparison = first_second_ID_comparison.drop([f'mgra_{second_ID}', f'year_{second_ID}', f'geozone_{second_ID}'], axis=1)\n",
    "    first_second_ID_comparison = first_second_ID_comparison.rename(columns={f'mgra_{first_ID}': 'mgra', f'year_{first_ID}': 'year', f'geozone_{first_ID}': 'geozone'})\n",
    "    \n",
    "    # Because we're summing, if using series 14 data, mgra's in multiple jurisdictions will be counted multiple times\n",
    "    first_second_ID_comparison = first_second_ID_comparison.groupby(['mgra', 'year']).sum()\n",
    "        \n",
    "    return first_second_ID_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_dfs_temp(comparison_first_ID_processed_data, comparison_second_ID_processed_data):\n",
    "    \"\"\"\n",
    "    Merges two mgra-level dataframes (generated by download_DS_data function) horizontally.\n",
    "    Returns a comparison table grouped by mgra and year.\n",
    "    \"\"\"\n",
    "    # Added geozone to merge keys to account for mgra's in multiple jurisdictions (or other geographical levels)\n",
    "    first_second_ID_comparison = comparison_first_ID_processed_data.merge(\n",
    "        comparison_second_ID_processed_data,\n",
    "        how='outer',\n",
    "        on=[f'mgra', f'year'],\n",
    "        suffixes=[f'_{first_ID}', f'_{second_ID}'])\n",
    "    \n",
    "    #print(first_second_ID_comparison)\n",
    "    \n",
    "    # Clean green combined\n",
    "    #first_second_ID_comparison = first_second_ID_comparison.drop([f'mgra_DS41', f'year_DS41'], axis=1)\n",
    "    #first_second_ID_comparison = first_second_ID_comparison.rename(columns={f'mgra_DS35': 'mgra', f'year_DS35': 'year'})\n",
    "    \n",
    "    # Because we're summing, if using series 14 data, mgra's in multiple jurisdictions will be counted multiple times\n",
    "    first_second_ID_comparison = first_second_ID_comparison.groupby(['mgra', 'year']).sum()\n",
    "        \n",
    "    return first_second_ID_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPA level Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cpa_aggregation(first_ID_df, second_ID_df, cpa_level):\n",
    "    \"\"\"\n",
    "    Joins Community Planning Area (CPA) information onto MGRA-level dataframes (generated by download_DS_data function).\n",
    "    Drops MGRA values that aren't in a CPA.\n",
    "    Returns a comparison table grouped by CPA and year.\n",
    "    \"\"\"\n",
    "    # Adding SQl Data (CPA) to first_id_df\n",
    "    comparison_first_ID_processed_data_cpa = first_ID_df.merge(cpa_level, how='left', on='mgra')\n",
    "    comparison_first_ID_processed_data_cpa = comparison_first_ID_processed_data_cpa[comparison_first_ID_processed_data_cpa['geozone'] != '*Not in a CPA*']\n",
    "\n",
    "    # Adding SQl Data (CPA) to second_id_df\n",
    "    comparison_second_ID_processed_data_cpa = second_ID_df.merge(cpa_level, how='left', on='mgra')\n",
    "    comparison_second_ID_processed_data_cpa = comparison_second_ID_processed_data_cpa[comparison_second_ID_processed_data_cpa['geozone'] != '*Not in a CPA*']\n",
    "\n",
    "    # Merge first_id_df and second_id_df together on mgra, year, and geozone\n",
    "    comparison_processed_data_cpa = comparison_first_ID_processed_data_cpa.merge(comparison_second_ID_processed_data_cpa, how='outer', on=['mgra', 'year', 'geozone'], suffixes=[f'_{first_ID}', f'_{second_ID}'])\n",
    "\n",
    "    # Drop the MGRA column because it isn't really a quantitative value\n",
    "    comparison_processed_data_cpa = comparison_processed_data_cpa.drop('mgra', axis=1)\n",
    "\n",
    "    # Aggregate the sum of features by geozone and year\n",
    "    comparison_processed_data_cpa = comparison_processed_data_cpa.groupby(['geozone', 'year']).sum()\n",
    "\n",
    "    # Rename index (geozone -> cpa)\n",
    "    comparison_processed_data_cpa.index.names = ['cpa', 'year']\n",
    "    \n",
    "    return comparison_processed_data_cpa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jurisdiction level Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jur_aggregation(first_ID_df, second_ID_df, jur_level):\n",
    "    \"\"\"\n",
    "    Joins Jurisdiction information onto MGRA-level dataframes (generated by download_DS_data function).\n",
    "    Returns a comparison table grouped by Jurisdiction and year.\n",
    "    \"\"\"\n",
    "    # Adding SQl Data (Jurisdiction) to first_id_df\n",
    "    comparison_first_ID_processed_data_jur = first_ID_df.merge(jur_level, how='left', on='mgra')\n",
    "    \n",
    "    # Adding SQl Data (Jurisdiction) to second_id_df\n",
    "    comparison_second_ID_processed_data_jur = second_ID_df.merge(jur_level, how='left', on='mgra')\n",
    "    \n",
    "    # Merge first_id_df and second_id_df together on mgra, year, and geozone\n",
    "    comparison_processed_data_jur = comparison_first_ID_processed_data_jur.merge(comparison_second_ID_processed_data_jur, how='outer', on=['mgra', 'year', 'geozone'], suffixes=[f'_{first_ID}', f'_{second_ID}'])\n",
    "    \n",
    "    # Drop the MGRA column because it isn't really a quantitative value\n",
    "    comparison_processed_data_jur = comparison_processed_data_jur.drop('mgra', axis=1)\n",
    "    \n",
    "    # Aggregate the sum of features by geozone and year\n",
    "    comparison_processed_data_jur = comparison_processed_data_jur.groupby(['geozone', 'year']).sum()\n",
    "    \n",
    "    # Rename index (geozone -> jurisdiction)\n",
    "    comparison_processed_data_jur.index.names = ['jurisdiction', 'year']\n",
    "        \n",
    "    return comparison_processed_data_jur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Diff File for all Geo Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_shared_features(features_first_ID, features_second_ID):\n",
    "    \"\"\"\n",
    "    (Comparison only)\n",
    "    Identifies non-shared features between two different DS_ID's.\n",
    "    \"\"\"\n",
    "    # Display non-shared features\n",
    "    return list(set(features_first_ID) ^ set(features_second_ID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_shared_years(first_ID_df, second_ID_df):\n",
    "    \"\"\"\n",
    "    (Comparison only)\n",
    "    Identifies non-shared years between two different DS_ID's.\n",
    "    \"\"\"\n",
    "    # Display non-shared years\n",
    "    return set(list(first_ID_df['year'].unique())) ^ set(list(second_ID_df['year'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_diff(features_first_ID, features_second_ID, first_second_ID_comparison):\n",
    "    \"\"\"\n",
    "    (Comparison only)\n",
    "    Returns a comparison table where the second_ID values are subtracted from the first_ID values.\n",
    "    \"\"\"\n",
    "    # Finding features common to both DSID data frames\n",
    "    first_ID_unique = set(features_first_ID)\n",
    "    intersection = first_ID_unique.intersection(features_second_ID)\n",
    "    shared_features = list(intersection)\n",
    "    \n",
    "    # Calculate diff values between the two DS_ID's\n",
    "    diff_df = pd.DataFrame()\n",
    "\n",
    "    # NOTE: Subtracts second DS ID from first DS ID. If negative, then second DS ID was greater than first DS ID.\n",
    "    for column in [col for col in features_first_ID if col in features_second_ID]:\n",
    "        diff_df[f'{column}_diff'] = first_second_ID_comparison[f'{column}_{first_ID}'] - first_second_ID_comparison[f'{column}_{second_ID}']\n",
    "        \n",
    "    return diff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_diff_temp(features_first_ID, features_second_ID, first_second_ID_comparison):\n",
    "    \"\"\"\n",
    "    (Comparison only)\n",
    "    Returns a comparison table where the second_ID values are subtracted from the first_ID values.\n",
    "    \"\"\"\n",
    "    # Finding features common to both DSID data frames\n",
    "    #first_ID_unique = set(features_first_ID)\n",
    "    #intersection = first_ID_unique.intersection(features_second_ID)\n",
    "    \n",
    "    shared_feats = [col for col in features_first_ID if col in features_second_ID]\n",
    "    \n",
    "    #shared_features = list(intersection)\n",
    "    \n",
    "    # Calculate diff values between the two DS_ID's\n",
    "    diff_df = pd.DataFrame()\n",
    "\n",
    "    # NOTE: Subtracts second DS ID from first DS ID. If negative, then second DS ID was greater than first DS ID.\n",
    "    for column in shared_feats:\n",
    "        diff_df[f'{column}_diff'] = first_second_ID_comparison[f'{column}_{first_ID}'] - first_second_ID_comparison[f'{column}_{second_ID}']\n",
    "        \n",
    "    return diff_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Region level Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_aggregation(first_ID_df, second_ID_df):\n",
    "    \"\"\"\n",
    "    Sums the entire MGRA-level dataframes (generated by download_DS_data function) by column to get region values.\n",
    "    Returns a comparison table grouped by year.\n",
    "    \"\"\"\n",
    "    # Merge first_id_df and second_id_df together on mgra and year\n",
    "    comparison_processed_data_reg = first_ID_df.merge(second_ID_df, how='outer', on=['mgra', 'year'], suffixes=[f'_{first_ID}', f'_{second_ID}'])\n",
    "    \n",
    "    # Aggregate the sum of features by year\n",
    "    comparison_processed_data_reg = comparison_processed_data_reg.groupby('year').sum()\n",
    "    \n",
    "    # Drop the MGRA column because it isn't really a quantitative value\n",
    "    comparison_processed_data_reg = comparison_processed_data_reg.drop('mgra', axis=1)\n",
    "        \n",
    "    return comparison_processed_data_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe config argument?\n",
    "def download_DS_data(ds_ID, jur_level):\n",
    "    \"\"\"\n",
    "    Downloads DS_ID csv data from SANDAG's T drive, formatted for non-MGRA series 14 data.\n",
    "    Returns processed data (merged with jurisdiction data and DS labeled), unprocessed data, and the features in the\n",
    "    dataset.\n",
    "    \"\"\"\n",
    "    datafiles = config[ds_ID].items()\n",
    "    \n",
    "    comparison_no_geozone_df = pd.DataFrame()\n",
    "    for year, file_name in datafiles:\n",
    "        working_df = pd.read_csv(file_name)\n",
    "        working_df['year'] = year[-4:]\n",
    "        comparison_no_geozone_df = comparison_no_geozone_df.append(working_df)\n",
    "        \n",
    "    # prepare column renaming\n",
    "    land_use_key = {}\n",
    "    for col in b.columns:\n",
    "        # unsure if this catches all columns\n",
    "        if len(col.split('_')) > 1 and col.split('_')[1] in land_use_key_incomplete.keys():\n",
    "            new_col = f\"{col.split('_')[0]}_{land_use_key_incomplete[col.split('_')[1]]}\"\n",
    "            land_use_key[col] = new_col\n",
    "    \n",
    "    # rename columns from sql data\n",
    "    comparison_no_geozone_df = comparison_no_geozone_df.rename(columns=housing_key)\n",
    "    comparison_no_geozone_df = comparison_no_geozone_df.rename(columns=income_key)\n",
    "    comparison_no_geozone_df = comparison_no_geozone_df.rename(columns=land_use_key)\n",
    "    \n",
    "    # Save the features_first_ID for future use (Used when creating the diff file)\n",
    "    features = comparison_no_geozone_df.drop(['mgra', 'year'], axis=1).columns\n",
    "    \n",
    "    comparison_no_geozone = copy.deepcopy(comparison_no_geozone_df)\n",
    "    \n",
    "    # Adding SQl Data to first_id_df\n",
    "    comparison_processed_data = comparison_no_geozone.merge(jur_level, how='left', on='mgra')\n",
    "    \n",
    "    # making it original\n",
    "    comparison_processed_data.columns = [x + f'_{ds_ID}' for x in comparison_processed_data.columns]\n",
    "        \n",
    "    return comparison_processed_data, comparison_no_geozone_df, features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPA Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cpa_aggregation_ind(first_ID_df, cpa_level):\n",
    "    \"\"\"\n",
    "    Joins Community Planning Area (CPA) information onto an MGRA-level dataframe (generated by download_DS_data function).\n",
    "    Drops MGRA values that aren't in a CPA.\n",
    "    Returns a table containing aggregated CPA values grouped by CPA and year.\n",
    "    \"\"\"\n",
    "    # Adding SQl Data (CPA) to first_id_df\n",
    "    comparison_first_ID_processed_data_cpa = first_ID_df.merge(cpa_level, how='left', on='mgra')\n",
    "    comparison_first_ID_processed_data_cpa = comparison_first_ID_processed_data_cpa[comparison_first_ID_processed_data_cpa['geozone'] != '*Not in a CPA*']\n",
    "\n",
    "    # Drop the MGRA column because it isn't really a quantitative value\n",
    "    comparison_processed_data_cpa = comparison_first_ID_processed_data_cpa.drop('mgra', axis=1)\n",
    "\n",
    "    # Aggregate the sum of features by geozone and year\n",
    "    comparison_processed_data_cpa = comparison_processed_data_cpa.groupby(['geozone', 'year']).sum()\n",
    "\n",
    "    # Rename index (geozone -> cpa)\n",
    "    comparison_processed_data_cpa.index.names = ['cpa', 'year']\n",
    "    \n",
    "    return comparison_processed_data_cpa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jurisdiction level Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jur_aggregation_ind(first_ID_df, jur_level):\n",
    "    \"\"\"\n",
    "    Joins Jurisdiction information onto an MGRA-level dataframe (generated by download_DS_data function).\n",
    "    Returns a table containing aggregated jurisdiction values grouped by jurisdiction and year.\n",
    "    \"\"\"\n",
    "    # Adding SQl Data (Jurisdiction) to first_id_df\n",
    "    comparison_first_ID_processed_data_jur = first_ID_df.merge(jur_level, how='left', on='mgra')\n",
    "    \n",
    "    # Drop the MGRA column because it isn't really a quantitative value\n",
    "    comparison_processed_data_jur = comparison_first_ID_processed_data_jur.drop('mgra', axis=1)\n",
    "    \n",
    "    # Aggregate the sum of features by geozone and year\n",
    "    comparison_processed_data_jur = comparison_processed_data_jur.groupby(['geozone', 'year']).sum()\n",
    "    \n",
    "    # Rename index (geozone -> jurisdiction)\n",
    "    comparison_processed_data_jur.index.names = ['jurisdiction', 'year']\n",
    "        \n",
    "    return comparison_processed_data_jur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Region level Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_aggregation_ind(first_ID_df):\n",
    "    \"\"\"\n",
    "    Sums the entire MGRA-level dataframe (generated by download_DS_data function) by column to get region values.\n",
    "    Returns a table containing aggregated mgra values grouped by year.\n",
    "    \"\"\"\n",
    "    # Aggregate the sum of features by year\n",
    "    comparison_processed_data_reg = first_ID_df.groupby('year').sum()\n",
    "    \n",
    "    # Drop the MGRA column because it isn't really a quantitative value\n",
    "    comparison_processed_data_reg = comparison_processed_data_reg.drop('mgra', axis=1)\n",
    "        \n",
    "    return comparison_processed_data_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pulling Info From YML File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Localise with . files \n",
    "# config_filename = 'C:/Users/cra/OneDrive - San Diego Association of Governments/DS41_42/ds41_42_config.yml'\n",
    "config_filename = './ds_config.yml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config_filename, \"r\") as yml_file:\n",
    "    config = yaml.safe_load(yml_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading SQL Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Decide when/how we read mgra_series value (we can solely identify series 14 using range of DS values i think)\n",
    "# Future mgra_series should not need mgra_id implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mgra_series = value \n",
    "# maybe from yml config?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = pyodbc.connect('Driver={ODBC Driver 17 for SQL Server};'\n",
    "                      'Server=DDAMWSQL16.sandag.org;'\n",
    "                      'Database=demographic_warehouse;'\n",
    "                      'Trusted_Connection=yes;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if mgra_series == 14:\n",
    "#     query_all = \"SELECT mgra_id, geotype, geozone FROM demographic_warehouse.dim.mgra WHERE series = 14 AND (geotype='cpa' OR geotype='jurisdiction')\" #Remove the last and part when I do this for real\n",
    "# else:\n",
    "#     # replace with bottom code once mgra_series gets implemented\n",
    "#     query_all = \"SELECT mgra, geotype, geozone FROM demographic_warehouse.dim.mgra WHERE series = 14 AND (geotype='cpa' OR geotype='jurisdiction')\" #Remove the last and part when I do this for real\n",
    "#     #query_all = f\"SELECT mgra, geotype, geozone FROM demographic_warehouse.dim.mgra WHERE series = {mgra_series} AND (geotype='cpa' OR geotype='jurisdiction')\" #Remove the last and part when I do this for real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_all = \"SELECT mgra, geotype, geozone FROM demographic_warehouse.dim.mgra WHERE series = 14 AND (geotype='cpa' OR geotype='jurisdiction')\" #Remove the last and part when I do this for real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query = pd.read_sql_query(query_all,conn)\n",
    "sql_df_all = pd.DataFrame(sql_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQl Data at different levels\n",
    "jur_level = sql_df_all[sql_df_all['geotype']=='jurisdiction'].drop('geotype', axis=1).drop_duplicates()\n",
    "cpa_level = sql_df_all[sql_df_all['geotype']=='cpa'].drop('geotype', axis=1).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hh, gq_mil, gq_college, and gq_other sql query\n",
    "housing_query = \"SELECT short_name, long_name FROM demographic_warehouse.dim.housing_type\"\n",
    "income_query = \"SELECT TOP(10) [income_group], [name], [constant_dollars_year]\\\n",
    " FROM [demographic_warehouse].[dim].[income_group]\\\n",
    " WHERE [constant_dollars_year] = 2010\"\n",
    "land_use_query = \"SELECT [land_use_type_id]\\\n",
    "      ,[short_name]\\\n",
    "      ,[long_name]\\\n",
    "  FROM [demographic_warehouse].[dim].[land_use_type]\"\n",
    "employment_query = \"SELECT TOP (1000) [employment_type_id]\\\n",
    "      ,[short_name]\\\n",
    "      ,[full_name]\\\n",
    "      ,[civilian]\\\n",
    "  FROM [demographic_warehouse].[dim].[employment_type]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_info = pd.read_sql_query(housing_query,conn)\n",
    "sql_housing_info = pd.DataFrame(housing_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important to avoid Latex formatting (with dollar signs)\n",
    "pd.options.display.html.use_mathjax = False\n",
    "income_info = pd.read_sql_query(income_query, conn)[['income_group', 'name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "land_use_info = pd.read_sql_query(land_use_query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "employment_info = pd.read_sql_query(employment_query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe tex2jax_ignore\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employment_type_id</th>\n",
       "      <th>short_name</th>\n",
       "      <th>full_name</th>\n",
       "      <th>civilian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>mil</td>\n",
       "      <td>Military</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>agmin</td>\n",
       "      <td>Agriculture and Mining</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>cons</td>\n",
       "      <td>Construction</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>mfg</td>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>whtrade</td>\n",
       "      <td>Wholesale Trade</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>retrade</td>\n",
       "      <td>Retail Trade</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>twu</td>\n",
       "      <td>Transporation, Warehousing, and Utilities</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>info</td>\n",
       "      <td>Information</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>fre</td>\n",
       "      <td>Finance and Real Estate</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>pbs</td>\n",
       "      <td>Professional and Business Services</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>edhs</td>\n",
       "      <td>Education and Healthcare</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>lh</td>\n",
       "      <td>Leisure and Hospitality</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>os</td>\n",
       "      <td>Office Services</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>gov</td>\n",
       "      <td>Government</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>sedw</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    employment_type_id short_name                                  full_name  \\\n",
       "0                    1        mil                                   Military   \n",
       "1                    2      agmin                     Agriculture and Mining   \n",
       "2                    3       cons                               Construction   \n",
       "3                    4        mfg                              Manufacturing   \n",
       "4                    5    whtrade                            Wholesale Trade   \n",
       "5                    6    retrade                               Retail Trade   \n",
       "6                    7        twu  Transporation, Warehousing, and Utilities   \n",
       "7                    8       info                                Information   \n",
       "8                    9        fre                    Finance and Real Estate   \n",
       "9                   10        pbs         Professional and Business Services   \n",
       "10                  11       edhs                   Education and Healthcare   \n",
       "11                  12         lh                    Leisure and Hospitality   \n",
       "12                  13         os                            Office Services   \n",
       "13                  14        gov                                 Government   \n",
       "14                  15       sedw                              Self-Employed   \n",
       "\n",
       "    civilian  \n",
       "0      False  \n",
       "1       True  \n",
       "2       True  \n",
       "3       True  \n",
       "4       True  \n",
       "5       True  \n",
       "6       True  \n",
       "7       True  \n",
       "8       True  \n",
       "9       True  \n",
       "10      True  \n",
       "11      True  \n",
       "12      True  \n",
       "13      True  \n",
       "14      True  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "employment_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_key = sql_housing_info.set_index('short_name').to_dict()['long_name']\n",
    "income_key_incomplete = income_info.set_index('income_group').to_dict()['name']\n",
    "land_use_key_incomplete = land_use_info.set_index('short_name').to_dict()['long_name']\n",
    "employment_key_incomplete = employment_info.set_index('short_name').to_dict()['full_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in housing_key.items():\n",
    "    housing_key[key] = f'{value} ({key})'\n",
    "    \n",
    "income_key = {}\n",
    "for key, value in income_key_incomplete.items():\n",
    "    income_key[f'i{key}'] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mil': 'Military',\n",
       " 'agmin': 'Agriculture and Mining',\n",
       " 'cons': 'Construction',\n",
       " 'mfg': 'Manufacturing',\n",
       " 'whtrade': 'Wholesale Trade',\n",
       " 'retrade': 'Retail Trade',\n",
       " 'twu': 'Transporation, Warehousing, and Utilities',\n",
       " 'info': 'Information',\n",
       " 'fre': 'Finance and Real Estate',\n",
       " 'pbs': 'Professional and Business Services',\n",
       " 'edhs': 'Education and Healthcare',\n",
       " 'lh': 'Leisure and Hospitality',\n",
       " 'os': 'Office Services',\n",
       " 'gov': 'Government',\n",
       " 'sedw': 'Self-Employed'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "employment_key_incomplete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe config argument?\n",
    "def download_DS_data(ds_ID, jur_level):\n",
    "    \"\"\"\n",
    "    Downloads DS_ID csv data from SANDAG's T drive, formatted for non-MGRA series 14 data.\n",
    "    Returns processed data (merged with jurisdiction data and DS labeled), unprocessed data, and the features in the\n",
    "    dataset.\n",
    "    \"\"\"\n",
    "    datafiles = config[ds_ID].items()\n",
    "    \n",
    "    comparison_no_geozone_df = pd.DataFrame()\n",
    "    for year, file_name in datafiles:\n",
    "        working_df = pd.read_csv(file_name)\n",
    "        working_df['year'] = year[-4:]\n",
    "        comparison_no_geozone_df = comparison_no_geozone_df.append(working_df)\n",
    "        \n",
    "    # prepare column renaming\n",
    "#     land_use_key = {}\n",
    "#     for col in comparison_no_geozone_df.columns:\n",
    "#         # unsure if this catches all columns\n",
    "#         if len(col.split('_')) > 1 and col.split('_')[1] in land_use_key_incomplete.keys():\n",
    "#             new_col = f\"{col.split('_')[0]}_{land_use_key_incomplete[col.split('_')[1]]}\"\n",
    "#             land_use_key[col] = new_col\n",
    "\n",
    "    \n",
    "                \n",
    "                \n",
    "                \n",
    "    \n",
    "\n",
    "    # rename columns from sql data\n",
    "    land_use_key = {}\n",
    "    for col in comparison_no_geozone_df.columns:\n",
    "        new_col = col.split('_')\n",
    "        for key, value in land_use_key_incomplete.items():\n",
    "            if key in new_col:\n",
    "                my_list = np.array(new_col)\n",
    "                my_list = np.where(my_list == key, value, my_list)\n",
    "                land_use_key[col] = '_'.join(my_list).replace(' ', '_')\n",
    "    \n",
    "    comparison_no_geozone_df = comparison_no_geozone_df.rename(columns=housing_key)\n",
    "    comparison_no_geozone_df = comparison_no_geozone_df.rename(columns=income_key)\n",
    "    comparison_no_geozone_df = comparison_no_geozone_df.rename(columns=land_use_key)\n",
    "    \n",
    "    employment_key = {}\n",
    "    for col in comparison_no_geozone_df.columns:\n",
    "        new_col = col.split('_')\n",
    "        for key, value in employment_key_incomplete.items():\n",
    "            if key in new_col:\n",
    "                my_list = np.array(new_col)\n",
    "                my_list = np.where(my_list == key, value, my_list)\n",
    "                employment_key[col] = '_'.join(my_list).replace(' ', '_')\n",
    "            \n",
    "    comparison_no_geozone_df = comparison_no_geozone_df.rename(columns=employment_key)\n",
    "    \n",
    "    # Save the features_first_ID for future use (Used when creating the diff file)\n",
    "    features = comparison_no_geozone_df.drop(['mgra', 'year'], axis=1).columns\n",
    "    \n",
    "    comparison_no_geozone = copy.deepcopy(comparison_no_geozone_df)\n",
    "    \n",
    "    # Adding SQl Data to first_id_df\n",
    "    comparison_processed_data = comparison_no_geozone.merge(jur_level, how='left', on='mgra')\n",
    "    \n",
    "    # making it original\n",
    "    comparison_processed_data.columns = [x + f'_{ds_ID}' for x in comparison_processed_data.columns]\n",
    "        \n",
    "    return comparison_processed_data, comparison_no_geozone_df, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c = download_DS_data('DS35', jur_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe tex2jax_ignore\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mgra</th>\n",
       "      <th>taz</th>\n",
       "      <th>hs</th>\n",
       "      <th>hs_Single_Family</th>\n",
       "      <th>hs_Multiple_Family</th>\n",
       "      <th>hs_Mobile_Homes</th>\n",
       "      <th>Household Population</th>\n",
       "      <th>hh_Single_Family</th>\n",
       "      <th>hh_Multiple_Family</th>\n",
       "      <th>hh_Mobile_Homes</th>\n",
       "      <th>...</th>\n",
       "      <th>upscaleroom</th>\n",
       "      <th>hotelroomtotal</th>\n",
       "      <th>luz_id</th>\n",
       "      <th>truckregiontype</th>\n",
       "      <th>district27</th>\n",
       "      <th>milestocoast</th>\n",
       "      <th>acres</th>\n",
       "      <th>effective_acres</th>\n",
       "      <th>land_acres</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3331</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>3.7997</td>\n",
       "      <td>16.615444</td>\n",
       "      <td>12.961482</td>\n",
       "      <td>16.615444</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3331</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>3.9761</td>\n",
       "      <td>19.519185</td>\n",
       "      <td>19.519185</td>\n",
       "      <td>19.519185</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3358</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>4.1939</td>\n",
       "      <td>27.845124</td>\n",
       "      <td>26.867938</td>\n",
       "      <td>27.845124</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3358</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>4.2782</td>\n",
       "      <td>7.976178</td>\n",
       "      <td>7.976178</td>\n",
       "      <td>7.976178</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3358</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>4.0062</td>\n",
       "      <td>7.072502</td>\n",
       "      <td>7.063693</td>\n",
       "      <td>7.072502</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22997</th>\n",
       "      <td>22998</td>\n",
       "      <td>1290</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6193</td>\n",
       "      <td>41.241522</td>\n",
       "      <td>26.863578</td>\n",
       "      <td>41.241522</td>\n",
       "      <td>2050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22998</th>\n",
       "      <td>22999</td>\n",
       "      <td>1290</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.3703</td>\n",
       "      <td>35.842780</td>\n",
       "      <td>30.635095</td>\n",
       "      <td>35.842780</td>\n",
       "      <td>2050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22999</th>\n",
       "      <td>23000</td>\n",
       "      <td>1290</td>\n",
       "      <td>131</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>126</td>\n",
       "      <td>126</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.1721</td>\n",
       "      <td>28.735275</td>\n",
       "      <td>16.109816</td>\n",
       "      <td>28.735275</td>\n",
       "      <td>2050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23000</th>\n",
       "      <td>23001</td>\n",
       "      <td>1254</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.7063</td>\n",
       "      <td>41.006144</td>\n",
       "      <td>28.126056</td>\n",
       "      <td>41.006144</td>\n",
       "      <td>2050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23001</th>\n",
       "      <td>23002</td>\n",
       "      <td>1254</td>\n",
       "      <td>120</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "      <td>17</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.4553</td>\n",
       "      <td>50.823736</td>\n",
       "      <td>34.131049</td>\n",
       "      <td>50.823736</td>\n",
       "      <td>2050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>299026 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        mgra   taz   hs  hs_Single_Family  hs_Multiple_Family  \\\n",
       "0          1  3331   19                19                   0   \n",
       "1          2  3331   35                35                   0   \n",
       "2          3  3358   52                52                   0   \n",
       "3          4  3358   30                30                   0   \n",
       "4          5  3358   28                28                   0   \n",
       "...      ...   ...  ...               ...                 ...   \n",
       "22997  22998  1290   92                92                   0   \n",
       "22998  22999  1290    0                 0                   0   \n",
       "22999  23000  1290  131               131                   0   \n",
       "23000  23001  1254   85                85                   0   \n",
       "23001  23002  1254  120                20                 100   \n",
       "\n",
       "       hs_Mobile_Homes  Household Population  hh_Single_Family  \\\n",
       "0                    0                    18                18   \n",
       "1                    0                    34                34   \n",
       "2                    0                    52                52   \n",
       "3                    0                    30                30   \n",
       "4                    0                    28                28   \n",
       "...                ...                   ...               ...   \n",
       "22997                0                    87                87   \n",
       "22998                0                     0                 0   \n",
       "22999                0                   126               126   \n",
       "23000                0                    82                82   \n",
       "23001                0                   109                17   \n",
       "\n",
       "       hh_Multiple_Family  hh_Mobile_Homes  ...  upscaleroom  hotelroomtotal  \\\n",
       "0                       0                0  ...            0               0   \n",
       "1                       0                0  ...            0               0   \n",
       "2                       0                0  ...            0               0   \n",
       "3                       0                0  ...            0               0   \n",
       "4                       0                0  ...            0               0   \n",
       "...                   ...              ...  ...          ...             ...   \n",
       "22997                   0                0  ...            0               0   \n",
       "22998                   0                0  ...            0               0   \n",
       "22999                   0                0  ...            0               0   \n",
       "23000                   0                0  ...            0               0   \n",
       "23001                  92                0  ...            0               0   \n",
       "\n",
       "       luz_id  truckregiontype  district27  milestocoast      acres  \\\n",
       "0          95                1          27        3.7997  16.615444   \n",
       "1          95                1          27        3.9761  19.519185   \n",
       "2          95                1          27        4.1939  27.845124   \n",
       "3          95                1          27        4.2782   7.976178   \n",
       "4          95                1          27        4.0062   7.072502   \n",
       "...       ...              ...         ...           ...        ...   \n",
       "22997      14                1           1        2.6193  41.241522   \n",
       "22998      14                1           1        2.3703  35.842780   \n",
       "22999      14                1           1        2.1721  28.735275   \n",
       "23000      14                1           1        2.7063  41.006144   \n",
       "23001      14                1           1        2.4553  50.823736   \n",
       "\n",
       "       effective_acres  land_acres  year  \n",
       "0            12.961482   16.615444  2016  \n",
       "1            19.519185   19.519185  2016  \n",
       "2            26.867938   27.845124  2016  \n",
       "3             7.976178    7.976178  2016  \n",
       "4             7.063693    7.072502  2016  \n",
       "...                ...         ...   ...  \n",
       "22997        26.863578   41.241522  2050  \n",
       "22998        30.635095   35.842780  2050  \n",
       "22999        16.109816   28.735275  2050  \n",
       "23000        28.126056   41.006144  2050  \n",
       "23001        34.131049   50.823736  2050  \n",
       "\n",
       "[299026 rows x 105 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mgra\n",
      "taz\n",
      "hs\n",
      "hs_Single_Family\n",
      "hs_Multiple_Family\n",
      "hs_Mobile_Homes\n",
      "Household Population\n",
      "hh_Single_Family\n",
      "hh_Multiple_Family\n",
      "hh_Mobile_Homes\n",
      "gq_civ\n",
      "Group Quarters - Military\n",
      "Less than $15,000\n",
      "$15,000 to $29,999\n",
      "$30,000 to $44,999\n",
      "$45,000 to $59,999\n",
      "$60,000 to $74,999\n",
      "$75,000 to $99,999\n",
      "$100,000 to $124,999\n",
      "$125,000 to $149,999\n",
      "$150,000 to $199,999\n",
      "$200,000 or more\n",
      "hhs\n",
      "pop\n",
      "hhp\n",
      "emp_Agricultural_and_Extractive\n",
      "emp_const_non_bldg_prod\n",
      "emp_const_non_bldg_Office\n",
      "emp_utilities_prod\n",
      "emp_utilities_Office\n",
      "emp_const_bldg_prod\n",
      "emp_const_bldg_Office\n",
      "emp_Manufacturing_prod\n",
      "emp_Manufacturing_Office\n",
      "emp_whsle_whs\n",
      "emp_trans\n",
      "emp_retail\n",
      "emp_prof_bus_svcs\n",
      "emp_prof_bus_svcs_bldg_maint\n",
      "emp_pvt_ed_k12\n",
      "emp_pvt_ed_post_k12_Other_Residential\n",
      "emp_health\n",
      "emp_personal_svcs_Office\n",
      "emp_amusement\n",
      "emp_hotel\n",
      "emp_restaurant_bar\n",
      "emp_personal_svcs_retail\n",
      "emp_religious\n",
      "emp_pvt_hh\n",
      "emp_state_local_Government_ent\n",
      "emp_fed_non_Military\n",
      "emp_fed_Military\n",
      "emp_state_local_Government_blue\n",
      "emp_state_local_Government_white\n",
      "emp_public_ed\n",
      "emp_own_occ_dwell_mgmt\n",
      "emp_fed_Government_accts\n",
      "emp_st_lcl_Government_accts\n",
      "emp_cap_accts\n",
      "emp_total\n",
      "enrollgradekto8\n",
      "enrollgrade9to12\n",
      "collegeenroll\n",
      "othercollegeenroll\n",
      "adultschenrl\n",
      "ech_dist\n",
      "hch_dist\n",
      "pseudomsa\n",
      "parkarea\n",
      "hstallsoth\n",
      "hstallssam\n",
      "hparkcost\n",
      "numfreehrs\n",
      "dstallsoth\n",
      "dstallssam\n",
      "dparkcost\n",
      "mstallsoth\n",
      "mstallssam\n",
      "mparkcost\n",
      "totint\n",
      "duden\n",
      "empden\n",
      "popden\n",
      "retempden\n",
      "totintbin\n",
      "empdenbin\n",
      "dudenbin\n",
      "zip09\n",
      "parkactive\n",
      "openspaceparkpreserve\n",
      "beachactive\n",
      "budgetroom\n",
      "economyroom\n",
      "luxuryroom\n",
      "midpriceroom\n",
      "upscaleroom\n",
      "hotelroomtotal\n",
      "luz_id\n",
      "truckregiontype\n",
      "district27\n",
      "milestocoast\n",
      "acres\n",
      "effective_acres\n",
      "land_acres\n",
      "year\n"
     ]
    }
   ],
   "source": [
    "for col in b.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in b.columns:\n",
    "    new_col = col.split('_')\n",
    "    for key, value in land_use_key_incomplete.items():        \n",
    "        if key in new_col:\n",
    "            my_list = np.array(new_col)\n",
    "            my_list = np.where(my_list == key, value, my_list)\n",
    "            print('_'.join(my_list).replace(' ', '_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GUI Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare desired output options\n",
    "comparison_selection_list = ['mgra_both', 'cpa_both', 'jur_both', 'region_both', 'mgra_diff', 'cpa_diff', 'jur_diff', 'region_diff']\n",
    "individual_selection_list = ['mgra_ind', 'cpa_ind', 'jur_ind', 'region_ind']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_window():\n",
    "    \"\"\"\n",
    "    Creates SimplePyGUI window that enables user to select output path and output option (comparison or individual).\n",
    "    Returns click event as well as selected values (click event will indicate output option and values will indicate \n",
    "    output path).\n",
    "    \"\"\"\n",
    "    layout_first = [ \n",
    "        [sg.Text('Please Designate An Output Path (or leave blank to use local outputs folder)')],\n",
    "        [sg.Text('Output Path', size =(15, 1)), sg.FolderBrowse(key='output-path')],\n",
    "        [sg.Text('Select An Output Option')],\n",
    "        [sg.Button(button_text='Comparison', key='comparison-select'),\n",
    "         sg.Button(button_text='Individual', key='individual-select'),\n",
    "         sg.Cancel()]\n",
    "    ]\n",
    "    \n",
    "    window = sg.Window('Base window', layout_first, element_justification='c')\n",
    "    event, values = window.read()\n",
    "    window.close()\n",
    "\n",
    "    return event, values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assert_inputs(event, values, output_path, output_notes):\n",
    "    \"\"\"Assert that inputs are compatible and formatted correctly!\"\"\"\n",
    "    \n",
    "    if output_path == '':\n",
    "        if not os.path.exists('outputs'):\n",
    "            os.makedirs('outputs')\n",
    "        output_path = './outputs'\n",
    "    globals()['output_path'] = output_path\n",
    "    \n",
    "    output_notes.append(f'Output files are located in: {output_path}')\n",
    "    input_list = values['input_list']\n",
    "    \n",
    "    # Check to make sure there's at least one desired output\n",
    "    assert len(values['input_list']) >= 1, 'Please select at least one output.'\n",
    "\n",
    "    if event == 'comparison':\n",
    "        # check that there are exactly 2 ds_ids selected\n",
    "        assert len(values['DS_IDs']) == 2, 'Incorrect number of DS_IDs selected.'\n",
    "\n",
    "        ds_selection = values['DS_IDs']\n",
    "        ds_selection.sort(reverse=True)\n",
    "        \n",
    "        first_ID, second_ID = ds_selection[0], ds_selection[1]\n",
    "        globals()['first_ID'] = first_ID\n",
    "        globals()['second_ID'] = second_ID\n",
    "        return\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_outputs(event, created_dfs):\n",
    "    \"\"\"\n",
    "    Function that converts created dataframes into csv files.\n",
    "    \"\"\" \n",
    "    # comparison output\n",
    "    if event == 'comparison':\n",
    "        for df_name, df in created_dfs.items():\n",
    "            if 'diff' in df_name:\n",
    "                df.to_csv(f\"{output_path}/{df_name}_{first_ID}_minus_{second_ID}.csv\")\n",
    "            else:\n",
    "                df.to_csv(f\"{output_path}/{df_name}_{first_ID}_{second_ID}.csv\")\n",
    "        return\n",
    "    \n",
    "    # individual output\n",
    "    for df_name, df in created_dfs.items():\n",
    "        df.to_csv(f\"{output_path}/{df_name}_{individual_ID}.csv\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comparison_dfs(event, first_ID, second_ID, input_list, output_notes):\n",
    "    \"\"\"\n",
    "    (Comparison Only)\n",
    "    Function that runs through desired outputs and creates dataframes based on selected desired outputs. This function\n",
    "    also saves any notes that need to be displayed to the user.\n",
    "    \"\"\"\n",
    "    # download data for each ds_id\n",
    "    first_ID_processed, first_ID_unprocessed, first_ID_features = download_DS_data(first_ID, jur_level)\n",
    "    second_ID_processed, second_ID_unprocessed, second_ID_features = download_DS_data(second_ID, jur_level)\n",
    "    \n",
    "    unshared_features = non_shared_features(first_ID_features, second_ID_features)\n",
    "    if len(unshared_features) > 0:\n",
    "        output_notes.append(f'Unshared features: {\", \".join(unshared_features)}')\n",
    "    else:\n",
    "        output_notes.append('All features are shared.')\n",
    "              \n",
    "    unshared_years = non_shared_years(first_ID_unprocessed, second_ID_unprocessed)\n",
    "    if len(unshared_years) > 0:\n",
    "        output_notes.append(f'Unshared years: {\", \".join(unshared_years)}')\n",
    "    else:\n",
    "        output_notes.append('All years are shared.')\n",
    "                            \n",
    "    for df in input_list:\n",
    "        if df[-4:] == 'diff':\n",
    "            geo_level, df_type = df.split('_')\n",
    "            output_notes.append(f'Differences in diff files were generated by calculating: {first_ID} values - {second_ID} values.')\n",
    "            output_notes.append(f'The {first_ID} and {second_ID} combined dataframe has also been outputted as {geo_level}_both_{first_ID}_{second_ID}.csv for reference.')\n",
    "                            \n",
    "#     if any(df[-4:] == 'diff' for df in input_list):\n",
    "        \n",
    "#         output_notes.append(f'Differences in diff files were generated by calculating: {first_ID} values - {second_ID} values.')\n",
    "#         output_notes.append(f'The {first_ID} and {second_ID} combined dataframe has also been outputted as both_{first_ID}_{second_ID}.csv.')\n",
    "    \n",
    "    output_notes.append(f'Base year for {first_ID} is {[item[-4:] for item in config[first_ID].keys()][0]}.')\n",
    "    output_notes.append(f'Base year for {second_ID} is {[item[-4:] for item in config[second_ID].keys()][0]}.')\n",
    "\n",
    "    created = {}\n",
    "    if 'mgra_both' in input_list:\n",
    "        mgra_both = concat_dfs_temp(first_ID_unprocessed, second_ID_unprocessed)\n",
    "        created['mgra_both'] = mgra_both\n",
    "    if 'cpa_both' in input_list:\n",
    "        cpa_both = cpa_aggregation(first_ID_unprocessed, second_ID_unprocessed, cpa_level)\n",
    "        created['cpa_both'] = cpa_both\n",
    "    if 'jur_both' in input_list: \n",
    "        jur_both = jur_aggregation(first_ID_unprocessed, second_ID_unprocessed, jur_level)\n",
    "        created['jur_both'] = jur_both\n",
    "    if 'region_both' in input_list:\n",
    "        region_both = region_aggregation(first_ID_unprocessed, second_ID_unprocessed)\n",
    "        created['region_both'] = region_both\n",
    "    if 'mgra_diff' in input_list:\n",
    "        if 'mgra_both' not in input_list:\n",
    "            mgra_both = concat_dfs_temp(first_ID_unprocessed, second_ID_unprocessed)\n",
    "        mgra_diff = create_diff_temp(first_ID_features, second_ID_features, mgra_both)\n",
    "        created['mgra_diff'] = mgra_diff\n",
    "        created['mgra_both'] = mgra_both\n",
    "    if 'cpa_diff' in input_list:\n",
    "        if 'cpa_both' not in input_list:\n",
    "            cpa_both = cpa_aggregation(first_ID_unprocessed, second_ID_unprocessed, cpa_level)\n",
    "        cpa_diff = create_diff(first_ID_features, second_ID_features, cpa_both)                            \n",
    "        created['cpa_diff'] = cpa_diff\n",
    "        created['cpa_both'] = cpa_both\n",
    "    if 'jur_diff' in input_list:\n",
    "        if 'jur_both' not in input_list:\n",
    "            jur_both = jur_aggregation(first_ID_unprocessed, second_ID_unprocessed, jur_level)\n",
    "        jur_diff = create_diff(first_ID_features, second_ID_features, jur_both)\n",
    "        created['jur_diff'] = jur_diff\n",
    "        created['jur_both'] = jur_both\n",
    "    if 'region_diff' in input_list:\n",
    "        if 'region_both' not in input_list:\n",
    "            region_both = region_aggregation(first_ID_unprocessed, second_ID_unprocessed)\n",
    "        region_diff = create_diff(first_ID_features, second_ID_features, region_both)\n",
    "        created['region_diff'] = region_diff\n",
    "        created['region_both'] = region_both\n",
    "\n",
    "    generate_outputs(event, created)\n",
    "                            \n",
    "    print(f\"{first_ID} & {second_ID} outputs generated successfully!\")\n",
    "                            \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparison_window(output_path):\n",
    "    \"\"\"\n",
    "    Creates SimplePyGUI window that enables user to select multiple DS_ID's along with desired outputs. The window will\n",
    "    also have a console section where any output notes or errors will be displayed.\n",
    "    Returns click event as well as selected values (might remove return values since no purpose as of now).\n",
    "    \"\"\"\n",
    "    lb = sg.Listbox(values=comparison_selection_list, select_mode='multiple', size=(30, len(comparison_selection_list)+1), key='input_list')\n",
    "    \n",
    "    def select_all():\n",
    "        lb.set_value(comparison_selection_list)\n",
    "        return\n",
    "    def deselect_all():\n",
    "        lb.set_value([])\n",
    "        return\n",
    "    \n",
    "    layout_comparison = [\n",
    "        [sg.Button('Back', key='Back')],\n",
    "        [sg.Text('Please Select 2 DS_IDs')],\n",
    "        [sg.Listbox(values=(list(config.keys())[:-1]), select_mode='multiple', size=(30, len(config.keys())), key='DS_IDs')],\n",
    "        [sg.Text('Please Select Desired Outputs')],\n",
    "        [[sg.Button('Select All', target='input_list', key='select_all'), sg.Button('Clear All', target='input_list', key='clear_all')], lb],\n",
    "        [sg.Submit(key='comparison'), sg.Button('Cancel/Close', key='Cancel')],\n",
    "        [sg.Output(size=(100,20), key='output')]\n",
    "    ]\n",
    "    \n",
    "    window = sg.Window('Comparison window', layout_comparison, element_justification='c')\n",
    "    \n",
    "    while True: # Event Loop\n",
    "        event, values = window.Read()\n",
    "        if event in (None, 'Cancel', 'Back'):\n",
    "            break\n",
    "        if event == 'select_all':\n",
    "            select_all()\n",
    "        if event == 'clear_all':\n",
    "            deselect_all()\n",
    "        if event == 'comparison':\n",
    "            try:\n",
    "                output_notes = []\n",
    "                assert_inputs(event, values, output_path, output_notes)\n",
    "                print('Creating dataframes...')\n",
    "                create_comparison_dfs(event, first_ID, second_ID, values['input_list'], output_notes)\n",
    "                print()\n",
    "                print('\\n'.join(output_notes))\n",
    "                print()\n",
    "            except FileNotFoundError as f:\n",
    "                print('Please connect to the VPN. If connected, please check YML file datapaths.')\n",
    "            except Exception as e:\n",
    "                print(traceback.format_exc())\n",
    "            \n",
    "    window.Close()\n",
    "    window['output'].__del__()\n",
    "    \n",
    "    if event == 'Back':\n",
    "        initiate_window()\n",
    "    \n",
    "    return event, values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_individual_dfs(event, individual_IDs, input_list, output_notes):\n",
    "    \"\"\"\n",
    "    (Individual Only)\n",
    "    Function that runs through desired outputs and creates dataframes based on selected desired outputs. This function\n",
    "    also saves any notes that need to be displayed to the user.\n",
    "    \"\"\"\n",
    "    \n",
    "    for individual_ID in individual_IDs:\n",
    "        \n",
    "        globals()['individual_ID'] = individual_ID\n",
    "        \n",
    "        # download data for the ds_id\n",
    "        individual_ID_processed, individual_ID_unprocessed, individual_ID_features = download_DS_data(individual_ID, jur_level)\n",
    "\n",
    "        output_notes.append(f'Base year for {individual_ID} is {[item[-4:] for item in config[individual_ID].keys()][0]}.')\n",
    "\n",
    "        created = {}\n",
    "        if 'mgra_ind' in input_list:\n",
    "            mgra_ind = individual_ID_unprocessed.groupby(['mgra', 'year']).sum()\n",
    "            created['mgra_ind'] = mgra_ind\n",
    "        if 'cpa_ind' in input_list:\n",
    "            cpa_ind = cpa_aggregation_ind(individual_ID_unprocessed, cpa_level)\n",
    "            created['cpa_ind'] = cpa_ind\n",
    "        if 'jur_ind' in input_list:\n",
    "            jur_ind = jur_aggregation_ind(individual_ID_unprocessed, jur_level)\n",
    "            created['jur_ind'] = jur_ind\n",
    "        if 'region_ind' in input_list:\n",
    "            region_ind = region_aggregation_ind(individual_ID_unprocessed)\n",
    "            created['region_ind'] = region_ind\n",
    "\n",
    "        generate_outputs(event, created)\n",
    "        print(f\"{individual_ID} {', '.join(created.keys())} outputs generated successfully!\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def individual_window(output_path):\n",
    "    \"\"\"\n",
    "    Creates SimplePyGUI window that enables user to select a single DS_ID along with desired outputs. The window will\n",
    "    also have a console section where any output notes or errors will be displayed.\n",
    "    Returns click event as well as selected values (might remove return values since no purpose as of now).\n",
    "    \"\"\"\n",
    "    lb_options = sg.Listbox(values=individual_selection_list, select_mode='multiple', size=(30, len(individual_selection_list)+1), key='input_list')\n",
    "    lb_ds = sg.Listbox(values=(list(config.keys())[:-1]), select_mode='multiple', size=(30, len(config.keys())), key='individual_ID')\n",
    "    \n",
    "    def select_all_options():\n",
    "        lb_options.set_value(individual_selection_list)\n",
    "        return\n",
    "    def deselect_all_options():\n",
    "        lb_options.set_value([])\n",
    "        return\n",
    "    \n",
    "    def select_all_ds():\n",
    "        lb_ds.set_value(list(config.keys())[:-1])\n",
    "        return\n",
    "    def deselect_all_ds():\n",
    "        lb_ds.set_value([])\n",
    "        return\n",
    "        \n",
    "    layout_individual = [\n",
    "        [sg.Button('Back', key='Back')],\n",
    "        [sg.Text('Please Select DS_ID(s)')],\n",
    "        [[sg.Button('Select All', target='individual_ID', key='select_all_ds'), sg.Button('Clear All', target='individual_ID', key='clear_all_ds')], lb_ds],\n",
    "        [sg.Text('Please Select Desired Outputs')],\n",
    "        [[sg.Button('Select All', target='input_list', key='select_all'), sg.Button('Clear All', target='input_list', key='clear_all')], lb_options],\n",
    "        [sg.Submit(key='individual'), sg.Button('Cancel/Close', key='Cancel')],\n",
    "        [sg.Output(size=(100,20), key='output')]\n",
    "    ]\n",
    "    \n",
    "    window = sg.Window('Individual window', layout_individual, element_justification='c')\n",
    "    \n",
    "    while True: # Event Loop\n",
    "        event, values = window.Read()\n",
    "        if event in (None, 'Cancel', 'Back'):\n",
    "            break\n",
    "        if event == 'select_all':\n",
    "            select_all_options()\n",
    "        if event == 'clear_all':\n",
    "            deselect_all_options()\n",
    "        if event == 'select_all_ds':\n",
    "            select_all_ds()\n",
    "        if event == 'clear_all_ds':\n",
    "            deselect_all_ds()\n",
    "        if event == 'individual':\n",
    "            try:\n",
    "                output_notes = []\n",
    "                assert_inputs(event, values, output_path, output_notes)\n",
    "                print('Creating dataframes...')\n",
    "                create_individual_dfs(event, values['individual_ID'], values['input_list'], output_notes)\n",
    "                print()\n",
    "                print('\\n'.join(output_notes))\n",
    "                print()\n",
    "            except FileNotFoundError as f:\n",
    "                print('Please connect to the VPN. If connected, please check YML file datapaths.')\n",
    "            except Exception as e:\n",
    "                print(traceback.format_exc())\n",
    "\n",
    "    window.Close()\n",
    "    window['output'].__del__()\n",
    "    \n",
    "    if event == 'Back':\n",
    "        initiate_window()\n",
    "    \n",
    "    return event, values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initiate_window():\n",
    "    \"\"\"\n",
    "    Function that initiates the window flow process starting with the base window. Helps coordinate transfer from base\n",
    "    window to either comparison or individual window based on click event returned from base window.\n",
    "    \"\"\"\n",
    "    sg.theme('SandyBeach')\n",
    "    \n",
    "    event, values = base_window()\n",
    "    output_path = values['output-path']\n",
    "    while True:\n",
    "        if event in [None, 'Cancel']:\n",
    "            return\n",
    "        if event == 'comparison-select':\n",
    "            event, values = comparison_window(output_path)\n",
    "            return\n",
    "        if event == 'individual-select':\n",
    "            event, values = individual_window(output_path)\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initiate_window()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO List:\n",
    "- Figure out what other output notes we need (especially for individual comparisons)\n",
    "- consider csv outputs as inputs to power bi\n",
    "\n",
    "\n",
    "- add mgra_id grouping for series 14 ds_ids (do we have csv files for series 14 we can test out? I think the ones we have been using are series 13.)\n",
    "- use outer join for the comparisons (**done but need to check if it works as intended**)\n",
    "- adjust sql query to be any series (currently queries only series 14 i think)\n",
    "\n",
    "series 14 mgra to jurisdiction: even if mgra falls into multiple juris, there are scenarios that one juridiction would report 0 to account for duplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IDEAS to consider:\n",
    "\n",
    "- should we rename columns based on sql tables (for clarity on column meanings)? **Already done for housing cols but maybe there's more we can do**\n",
    "- generate outputs to different folders for comparison or individual?\n",
    "- should we order the DS_ID's in the selection list?\n",
    "- how are mgra csv files released? If there's a convention for folder file paths, maybe we could automate selection of new filepaths instead of using the yml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_check = pd.read_csv('./outputs/mgra_ind_DS35.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in temp_check.columns:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d60123f2ed8b63279fba5ddbefdeca593323e286d3975f7130d49323a9310301"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
