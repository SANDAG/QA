{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: The concat_dfs and create_diff functions are not-optimal for MGRA series 14, as they are designed for the anticipated MGRA series 15+. Therefore, we have created temp versions of these functions to use for MGRA series 14. When the series 15 gets released, these functions will need to be manually switched in the `GUI Implementation` section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#Libraries \n",
    "import os\n",
    "import pyodbc\n",
    "import glob\n",
    "import copy\n",
    "import PySimpleGUI as sg\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MGRA Level Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate both DS dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_dfs(comparison_first_ID_processed_data, comparison_second_ID_processed_data):\n",
    "    \"\"\"\n",
    "    Merges two mgra-level dataframes (generated by download_DS_data function) horizontally.\n",
    "    Returns a comparison table grouped by mgra and year.\n",
    "    \"\"\"\n",
    "    # Added geozone to merge keys to account for mgra's in multiple jurisdictions (or other geographical levels)\n",
    "    first_second_ID_comparison = comparison_first_ID_processed_data.merge(\n",
    "        comparison_second_ID_processed_data,\n",
    "        how='outer',\n",
    "        left_on=[f'mgra_{first_ID}',\n",
    "                 f'year_{first_ID}',\n",
    "                 f'geozone_{first_ID}'],\n",
    "        right_on=[f'mgra_{second_ID}',\n",
    "                 f'year_{second_ID}',\n",
    "                 f'geozone_{second_ID}'])\n",
    "    \n",
    "    # Clean green combined\n",
    "    first_second_ID_comparison = first_second_ID_comparison.drop([f'mgra_{second_ID}', f'year_{second_ID}', f'geozone_{second_ID}'], axis=1)\n",
    "    first_second_ID_comparison = first_second_ID_comparison.rename(columns={f'mgra_{first_ID}': 'mgra', f'year_{first_ID}': 'year', f'geozone_{first_ID}': 'geozone'})\n",
    "    \n",
    "    # Because we're summing, if using series 14 data, mgra's in multiple jurisdictions will be counted multiple times\n",
    "    first_second_ID_comparison = first_second_ID_comparison.groupby(['mgra', 'year']).sum()\n",
    "        \n",
    "    return first_second_ID_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## CPA level Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def cpa_aggregation(first_ID_df, second_ID_df, cpa_level):\n",
    "    \"\"\"\n",
    "    Joins Community Planning Area (CPA) information onto MGRA-level dataframes (generated by download_DS_data function).\n",
    "    Drops MGRA values that aren't in a CPA.\n",
    "    Returns a comparison table grouped by CPA and year.\n",
    "    \"\"\"\n",
    "    # Adding SQl Data (CPA) to first_id_df\n",
    "    comparison_first_ID_processed_data_cpa = first_ID_df.merge(cpa_level, how='left', on='mgra')\n",
    "    comparison_first_ID_processed_data_cpa = comparison_first_ID_processed_data_cpa[comparison_first_ID_processed_data_cpa['geozone'] != '*Not in a CPA*']\n",
    "\n",
    "    # Adding SQl Data (CPA) to second_id_df\n",
    "    comparison_second_ID_processed_data_cpa = second_ID_df.merge(cpa_level, how='left', on='mgra')\n",
    "    comparison_second_ID_processed_data_cpa = comparison_second_ID_processed_data_cpa[comparison_second_ID_processed_data_cpa['geozone'] != '*Not in a CPA*']\n",
    "\n",
    "    # Merge first_id_df and second_id_df together on mgra, year, and geozone\n",
    "    comparison_processed_data_cpa = comparison_first_ID_processed_data_cpa.merge(comparison_second_ID_processed_data_cpa, how='outer', on=['mgra', 'year', 'geozone'], suffixes=[f'_{first_ID}', f'_{second_ID}'])\n",
    "\n",
    "    # Drop the MGRA column because it isn't really a quantitative value\n",
    "    comparison_processed_data_cpa = comparison_processed_data_cpa.drop('mgra', axis=1)\n",
    "\n",
    "    # Aggregate the sum of features by geozone and year\n",
    "    comparison_processed_data_cpa = comparison_processed_data_cpa.groupby(['geozone', 'year']).sum()\n",
    "\n",
    "    # Rename index (geozone -> cpa)\n",
    "    comparison_processed_data_cpa.index.names = ['cpa', 'year']\n",
    "    \n",
    "    return comparison_processed_data_cpa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Jurisdiction level Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def jur_aggregation(first_ID_df, second_ID_df, jur_level):\n",
    "    \"\"\"\n",
    "    Joins Jurisdiction information onto MGRA-level dataframes (generated by download_DS_data function).\n",
    "    Returns a comparison table grouped by Jurisdiction and year.\n",
    "    \"\"\"\n",
    "    # Adding SQl Data (Jurisdiction) to first_id_df\n",
    "    comparison_first_ID_processed_data_jur = first_ID_df.merge(jur_level, how='left', on='mgra')\n",
    "    \n",
    "    # Adding SQl Data (Jurisdiction) to second_id_df\n",
    "    comparison_second_ID_processed_data_jur = second_ID_df.merge(jur_level, how='left', on='mgra')\n",
    "    \n",
    "    # Merge first_id_df and second_id_df together on mgra, year, and geozone\n",
    "    comparison_processed_data_jur = comparison_first_ID_processed_data_jur.merge(comparison_second_ID_processed_data_jur, how='outer', on=['mgra', 'year', 'geozone'], suffixes=[f'_{first_ID}', f'_{second_ID}'])\n",
    "    \n",
    "    # Drop the MGRA column because it isn't really a quantitative value\n",
    "    comparison_processed_data_jur = comparison_processed_data_jur.drop('mgra', axis=1)\n",
    "    \n",
    "    # Aggregate the sum of features by geozone and year\n",
    "    comparison_processed_data_jur = comparison_processed_data_jur.groupby(['geozone', 'year']).sum()\n",
    "    \n",
    "    # Rename index (geozone -> jurisdiction)\n",
    "    comparison_processed_data_jur.index.names = ['jurisdiction', 'year']\n",
    "        \n",
    "    return comparison_processed_data_jur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Diff File for all Geo Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_shared_features(features_first_ID, features_second_ID):\n",
    "    \"\"\"\n",
    "    (Comparison only)\n",
    "    Identifies non-shared features between two different DS_ID's.\n",
    "    \"\"\"\n",
    "    # Display non-shared features\n",
    "    return list(set(features_first_ID) ^ set(features_second_ID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_shared_years(first_ID_df, second_ID_df):\n",
    "    \"\"\"\n",
    "    (Comparison only)\n",
    "    Identifies non-shared years between two different DS_ID's.\n",
    "    \"\"\"\n",
    "    # Display non-shared years\n",
    "    return set(list(first_ID_df['year'].unique())) ^ set(list(second_ID_df['year'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_diff(features_first_ID, features_second_ID, first_second_ID_comparison):\n",
    "    \"\"\"\n",
    "    (Comparison only)\n",
    "    Returns a comparison table where the second_ID values are subtracted from the first_ID values.\n",
    "    \"\"\"\n",
    "    # Finding features common to both DSID data frames\n",
    "    first_ID_unique = set(features_first_ID)\n",
    "    intersection = first_ID_unique.intersection(features_second_ID)\n",
    "    shared_features = list(intersection)\n",
    "    \n",
    "    # Calculate diff values between the two DS_ID's\n",
    "    diff_df = pd.DataFrame()\n",
    "\n",
    "    # NOTE: Subtracts second DS ID from first DS ID. If negative, then second DS ID was greater than first DS ID.\n",
    "    for column in [col for col in features_first_ID if col in features_second_ID]:\n",
    "        diff_df[f'{column}_diff'] = first_second_ID_comparison[f'{column}_{first_ID}'] - first_second_ID_comparison[f'{column}_{second_ID}']\n",
    "        \n",
    "    return diff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_dfs_temp(comparison_first_ID_processed_data, comparison_second_ID_processed_data):\n",
    "    \"\"\"\n",
    "    Merges two mgra-level dataframes (generated by download_DS_data function) horizontally.\n",
    "    Returns a comparison table grouped by mgra and year.\n",
    "    \"\"\"\n",
    "    # Added geozone to merge keys to account for mgra's in multiple jurisdictions (or other geographical levels)\n",
    "    first_second_ID_comparison = comparison_first_ID_processed_data.merge(\n",
    "        comparison_second_ID_processed_data,\n",
    "        how='outer',\n",
    "        on=[f'mgra', f'year'],\n",
    "        suffixes=[f'_{first_ID}', f'_{second_ID}'])\n",
    "    \n",
    "    #print(first_second_ID_comparison)\n",
    "    \n",
    "    # Clean green combined\n",
    "    #first_second_ID_comparison = first_second_ID_comparison.drop([f'mgra_DS41', f'year_DS41'], axis=1)\n",
    "    #first_second_ID_comparison = first_second_ID_comparison.rename(columns={f'mgra_DS35': 'mgra', f'year_DS35': 'year'})\n",
    "    \n",
    "    # Because we're summing, if using series 14 data, mgra's in multiple jurisdictions will be counted multiple times\n",
    "    first_second_ID_comparison = first_second_ID_comparison.groupby(['mgra', 'year']).sum()\n",
    "        \n",
    "    return first_second_ID_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_diff_temp(features_first_ID, features_second_ID, first_second_ID_comparison):\n",
    "    \"\"\"\n",
    "    (Comparison only)\n",
    "    Returns a comparison table where the second_ID values are subtracted from the first_ID values.\n",
    "    \"\"\"\n",
    "    # Finding features common to both DSID data frames\n",
    "    #first_ID_unique = set(features_first_ID)\n",
    "    #intersection = first_ID_unique.intersection(features_second_ID)\n",
    "    \n",
    "    shared_feats = [col for col in features_first_ID if col in features_second_ID]\n",
    "    \n",
    "    #shared_features = list(intersection)\n",
    "    \n",
    "    # Calculate diff values between the two DS_ID's\n",
    "    diff_df = pd.DataFrame()\n",
    "\n",
    "    # NOTE: Subtracts second DS ID from first DS ID. If negative, then second DS ID was greater than first DS ID.\n",
    "    for column in shared_feats:\n",
    "        diff_df[f'{column}_diff'] = first_second_ID_comparison[f'{column}_{first_ID}'] - first_second_ID_comparison[f'{column}_{second_ID}']\n",
    "        \n",
    "    return diff_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a, b, c = download_DS_data('DS35', jur_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d, e, f = download_DS_data('DS41', jur_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#g = concat_dfs_temp(b, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#h = create_diff_temp(c, f, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Region level Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_aggregation(first_ID_df, second_ID_df):\n",
    "    \"\"\"\n",
    "    Sums the entire MGRA-level dataframes (generated by download_DS_data function) by column to get region values.\n",
    "    Returns a comparison table grouped by year.\n",
    "    \"\"\"\n",
    "    # Merge first_id_df and second_id_df together on mgra and year\n",
    "    comparison_processed_data_reg = first_ID_df.merge(second_ID_df, how='outer', on=['mgra', 'year'], suffixes=[f'_{first_ID}', f'_{second_ID}'])\n",
    "    \n",
    "    # Aggregate the sum of features by year\n",
    "    comparison_processed_data_reg = comparison_processed_data_reg.groupby('year').sum()\n",
    "    \n",
    "    # Drop the MGRA column because it isn't really a quantitative value\n",
    "    comparison_processed_data_reg = comparison_processed_data_reg.drop('mgra', axis=1)\n",
    "        \n",
    "    return comparison_processed_data_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Individual Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# maybe config argument?\n",
    "def download_DS_data(ds_ID, jur_level):\n",
    "    \"\"\"\n",
    "    Downloads DS_ID csv data from SANDAG's T drive, formatted for non-MGRA series 14 data.\n",
    "    Returns processed data (merged with jurisdiction data and DS labeled), unprocessed data, and the features in the\n",
    "    dataset.\n",
    "    \"\"\"\n",
    "    datafiles = config[ds_ID].items()\n",
    "    \n",
    "    comparison_no_geozone_df = pd.DataFrame()\n",
    "    for year, file_name in datafiles:\n",
    "        working_df = pd.read_csv(file_name)\n",
    "        working_df['year'] = year[-4:]\n",
    "        comparison_no_geozone_df = comparison_no_geozone_df.append(working_df)\n",
    "    \n",
    "    # rename housing columns from sql data\n",
    "    comparison_no_geozone_df = comparison_no_geozone_df.rename(columns=housing_key)\n",
    "    \n",
    "    # Save the features_first_ID for future use (Used when creating the diff file)\n",
    "    features = comparison_no_geozone_df.drop(['mgra', 'year'], axis=1).columns\n",
    "    \n",
    "    comparison_no_geozone = copy.deepcopy(comparison_no_geozone_df)\n",
    "    \n",
    "    # Adding SQl Data to first_id_df\n",
    "    comparison_processed_data = comparison_no_geozone.merge(jur_level, how='left', on='mgra')\n",
    "    \n",
    "    # making it original\n",
    "    comparison_processed_data.columns = [x + f'_{ds_ID}' for x in comparison_processed_data.columns]\n",
    "        \n",
    "    return comparison_processed_data, comparison_no_geozone_df, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def download_series14_data(ds_ID, jur_level_14):\n",
    "    \"\"\"\n",
    "    Downloads DS_ID csv data from SANDAG's T drive, formatted for MGRA series 14 data (using mgra_id).\n",
    "    Returns processed data (merged with jurisdiction data and DS labeled), unprocessed data, and the features in the\n",
    "    dataset.\n",
    "    \"\"\"\n",
    "    datafiles = config[ds_ID].values()\n",
    "    \n",
    "    comparison_no_geozone_df = pd.DataFrame()\n",
    "    for file_name in datafiles:\n",
    "        working_df = pd.read_csv(file_name)\n",
    "        working_df['year'] = f\"{file_name[-11:-7]}\"\n",
    "        comparison_no_geozone_df = comparison_no_geozone_df.append(working_df)\n",
    "\n",
    "    # Save the features_first_ID for future use (Used when creating the diff file)\n",
    "    features = comparison_no_geozone_df.drop(['mgra_id', 'year'], axis=1).columns\n",
    "\n",
    "    comparison_no_geozone = copy.deepcopy(comparison_no_geozone_df)\n",
    "\n",
    "    # Adding SQl Data to first_id_df\n",
    "    comparison_processed_data = comparison_no_geozone.merge(jur_level_14, how='left', on='mgra_id')\n",
    "    comparison_processed_data = comparison_processed_data.rename({'mgra_id': 'mgra'})\n",
    "\n",
    "    # making it original\n",
    "    comparison_processed_data.columns = [x + f'_{ds_ID}' for x in comparison_processed_data.columns]\n",
    "\n",
    "    return comparison_processed_data, comparison_no_geozone_df, features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## CPA Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def cpa_aggregation_ind(first_ID_df, cpa_level):\n",
    "    \"\"\"\n",
    "    Joins Community Planning Area (CPA) information onto an MGRA-level dataframe (generated by download_DS_data function).\n",
    "    Drops MGRA values that aren't in a CPA.\n",
    "    Returns a table containing aggregated CPA values grouped by CPA and year.\n",
    "    \"\"\"\n",
    "    # Adding SQl Data (CPA) to first_id_df\n",
    "    comparison_first_ID_processed_data_cpa = first_ID_df.merge(cpa_level, how='left', on='mgra')\n",
    "    comparison_first_ID_processed_data_cpa = comparison_first_ID_processed_data_cpa[comparison_first_ID_processed_data_cpa['geozone'] != '*Not in a CPA*']\n",
    "\n",
    "    # Drop the MGRA column because it isn't really a quantitative value\n",
    "    comparison_processed_data_cpa = comparison_first_ID_processed_data_cpa.drop('mgra', axis=1)\n",
    "\n",
    "    # Aggregate the sum of features by geozone and year\n",
    "    comparison_processed_data_cpa = comparison_processed_data_cpa.groupby(['geozone', 'year']).sum()\n",
    "\n",
    "    # Rename index (geozone -> cpa)\n",
    "    comparison_processed_data_cpa.index.names = ['cpa', 'year']\n",
    "    \n",
    "    return comparison_processed_data_cpa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Jurisdiction level Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def jur_aggregation_ind(first_ID_df, jur_level):\n",
    "    \"\"\"\n",
    "    Joins Jurisdiction information onto an MGRA-level dataframe (generated by download_DS_data function).\n",
    "    Returns a table containing aggregated jurisdiction values grouped by jurisdiction and year.\n",
    "    \"\"\"\n",
    "    # Adding SQl Data (Jurisdiction) to first_id_df\n",
    "    comparison_first_ID_processed_data_jur = first_ID_df.merge(jur_level, how='left', on='mgra')\n",
    "    \n",
    "    # Drop the MGRA column because it isn't really a quantitative value\n",
    "    comparison_processed_data_jur = comparison_first_ID_processed_data_jur.drop('mgra', axis=1)\n",
    "    \n",
    "    # Aggregate the sum of features by geozone and year\n",
    "    comparison_processed_data_jur = comparison_processed_data_jur.groupby(['geozone', 'year']).sum()\n",
    "    \n",
    "    # Rename index (geozone -> jurisdiction)\n",
    "    comparison_processed_data_jur.index.names = ['jurisdiction', 'year']\n",
    "        \n",
    "    return comparison_processed_data_jur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Region level Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def region_aggregation_ind(first_ID_df):\n",
    "    \"\"\"\n",
    "    Sums the entire MGRA-level dataframe (generated by download_DS_data function) by column to get region values.\n",
    "    Returns a table containing aggregated mgra values grouped by year.\n",
    "    \"\"\"\n",
    "    # Aggregate the sum of features by year\n",
    "    comparison_processed_data_reg = first_ID_df.groupby('year').sum()\n",
    "    \n",
    "    # Drop the MGRA column because it isn't really a quantitative value\n",
    "    comparison_processed_data_reg = comparison_processed_data_reg.drop('mgra', axis=1)\n",
    "        \n",
    "    return comparison_processed_data_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Pulling Info From YML File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Localise with . files \n",
    "# config_filename = 'C:/Users/cra/OneDrive - San Diego Association of Governments/DS41_42/ds41_42_config.yml'\n",
    "config_filename = './ds_config.yml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open(config_filename, \"r\") as yml_file:\n",
    "    config = yaml.safe_load(yml_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Downloading SQL Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# TODO: Decide when/how we read mgra_series value (we can solely identify series 14 using range of DS values i think)\n",
    "# Future mgra_series should not need mgra_id implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#mgra_series = value \n",
    "# maybe from yml config?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "conn = pyodbc.connect('Driver={ODBC Driver 17 for SQL Server};'\n",
    "                      'Server=DDAMWSQL16.sandag.org;'\n",
    "                      'Database=demographic_warehouse;'\n",
    "                      'Trusted_Connection=yes;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# if mgra_series == 14:\n",
    "#     query_all = \"SELECT mgra_id, geotype, geozone FROM demographic_warehouse.dim.mgra WHERE series = 14 AND (geotype='cpa' OR geotype='jurisdiction')\" #Remove the last and part when I do this for real\n",
    "# else:\n",
    "#     # replace with bottom code once mgra_series gets implemented\n",
    "#     query_all = \"SELECT mgra, geotype, geozone FROM demographic_warehouse.dim.mgra WHERE series = 14 AND (geotype='cpa' OR geotype='jurisdiction')\" #Remove the last and part when I do this for real\n",
    "#     #query_all = f\"SELECT mgra, geotype, geozone FROM demographic_warehouse.dim.mgra WHERE series = {mgra_series} AND (geotype='cpa' OR geotype='jurisdiction')\" #Remove the last and part when I do this for real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "query_all = \"SELECT mgra, geotype, geozone FROM demographic_warehouse.dim.mgra WHERE series = 14 AND (geotype='cpa' OR geotype='jurisdiction')\" #Remove the last and part when I do this for real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sql_query = pd.read_sql_query(query_all,conn)\n",
    "sql_df_all = pd.DataFrame(sql_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# SQl Data at different levels\n",
    "jur_level = sql_df_all[sql_df_all['geotype']=='jurisdiction'].drop('geotype', axis=1).drop_duplicates()\n",
    "cpa_level = sql_df_all[sql_df_all['geotype']=='cpa'].drop('geotype', axis=1).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# hh, gq_mil, gq_college, and gq_other sql query\n",
    "housing_query = \"SELECT short_name, long_name FROM demographic_warehouse.dim.housing_type\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "housing_info = pd.read_sql_query(housing_query,conn)\n",
    "sql_housing_info = pd.DataFrame(housing_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "housing_key = sql_housing_info.set_index('short_name').to_dict()['long_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for key, value in housing_key.items():\n",
    "    housing_key[key] = f'{value} ({key})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hh': 'Household Population (hh)',\n",
       " 'gq_mil': 'Group Quarters - Military (gq_mil)',\n",
       " 'gq_college': 'Group Quarters - College (gq_college)',\n",
       " 'gq_other': 'Group Quarters - Other (gq_other)'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GUI Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare desired output options\n",
    "comparison_selection_list = ['mgra_both', 'cpa_both', 'jur_both', 'region_both', 'mgra_diff', 'cpa_diff', 'jur_diff', 'region_diff']\n",
    "individual_selection_list = ['mgra_ind', 'cpa_ind', 'jur_ind', 'region_ind']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_window():\n",
    "    \"\"\"\n",
    "    Creates SimplePyGUI window that enables user to select output path and output option (comparison or individual).\n",
    "    Returns click event as well as selected values (click event will indicate output option and values will indicate \n",
    "    output path).\n",
    "    \"\"\"\n",
    "    layout_first = [ \n",
    "        [sg.Text('Please Designate An Output Path (or leave blank to use local outputs folder)')],\n",
    "        [sg.Text('Output Path', size =(15, 1)), sg.FolderBrowse(key='output-path')],\n",
    "        [sg.Text('Select An Output Option')],\n",
    "        [sg.Button(button_text='Comparison', key='comparison-select'),\n",
    "         sg.Button(button_text='Individual', key='individual-select'),\n",
    "         sg.Cancel()]\n",
    "    ]\n",
    "    \n",
    "    window = sg.Window('Base window', layout_first, element_justification='c')\n",
    "    event, values = window.read()\n",
    "    window.close()\n",
    "\n",
    "    return event, values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assert_inputs(event, values, output_path, output_notes):\n",
    "    \"\"\"Assert that inputs are compatible and formatted correctly!\"\"\"\n",
    "    \n",
    "    if output_path == '':\n",
    "        if not os.path.exists('outputs'):\n",
    "            os.makedirs('outputs')\n",
    "        output_path = './outputs'\n",
    "    globals()['output_path'] = output_path\n",
    "    \n",
    "    output_notes.append(f'Output files are located in: {output_path}')\n",
    "    input_list = values['input_list']\n",
    "    \n",
    "    # Check to make sure there's at least one desired output\n",
    "    assert len(values['input_list']) >= 1, 'Please select at least one output.'\n",
    "\n",
    "    if event == 'comparison':\n",
    "        # check that there are exactly 2 ds_ids selected\n",
    "        assert len(values['DS_IDs']) == 2, 'Incorrect number of DS_IDs selected.'\n",
    "\n",
    "        ds_selection = values['DS_IDs']\n",
    "        ds_selection.sort(reverse=True)\n",
    "        \n",
    "        first_ID, second_ID = ds_selection[0], ds_selection[1]\n",
    "        globals()['first_ID'] = first_ID\n",
    "        globals()['second_ID'] = second_ID\n",
    "        return\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab = 'hello'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'el' in ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_outputs(event, created_dfs):\n",
    "    \"\"\"\n",
    "    Function that converts created dataframes into csv files.\n",
    "    \"\"\" \n",
    "    # comparison output\n",
    "    if event == 'comparison':\n",
    "        for df_name, df in created_dfs.items():\n",
    "            if 'diff' in df_name:\n",
    "                df.to_csv(f\"{output_path}/{df_name}_{first_ID}_minus_{second_ID}.csv\")\n",
    "            else:\n",
    "                df.to_csv(f\"{output_path}/{df_name}_{first_ID}_{second_ID}.csv\")\n",
    "        return\n",
    "    \n",
    "    # individual output\n",
    "    for df_name, df in created_dfs.items():\n",
    "        df.to_csv(f\"{output_path}/{df_name}_{individual_ID}.csv\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comparison_dfs(event, first_ID, second_ID, input_list, output_notes):\n",
    "    \"\"\"\n",
    "    (Comparison Only)\n",
    "    Function that runs through desired outputs and creates dataframes based on selected desired outputs. This function\n",
    "    also saves any notes that need to be displayed to the user.\n",
    "    \"\"\"\n",
    "    # download data for each ds_id\n",
    "    first_ID_processed, first_ID_unprocessed, first_ID_features = download_DS_data(first_ID, jur_level)\n",
    "    second_ID_processed, second_ID_unprocessed, second_ID_features = download_DS_data(second_ID, jur_level)\n",
    "    \n",
    "    unshared_features = non_shared_features(first_ID_features, second_ID_features)\n",
    "    if len(unshared_features) > 0:\n",
    "        output_notes.append(f'Unshared features: {\", \".join(unshared_features)}')\n",
    "    else:\n",
    "        output_notes.append('All features are shared.')\n",
    "              \n",
    "    unshared_years = non_shared_years(first_ID_unprocessed, second_ID_unprocessed)\n",
    "    if len(unshared_years) > 0:\n",
    "        output_notes.append(f'Unshared years: {\", \".join(unshared_years)}')\n",
    "    else:\n",
    "        output_notes.append('All years are shared.')\n",
    "                            \n",
    "    if any(df[-4:] == 'diff' for df in input_list):\n",
    "        output_notes.append(f'Differences in diff files were generated by calculating: {first_ID} values - {second_ID} values.')\n",
    "    \n",
    "    output_notes.append(f'Base year for {first_ID} is {[item[-4:] for item in config[first_ID].keys()][0]}.')\n",
    "    output_notes.append(f'Base year for {second_ID} is {[item[-4:] for item in config[second_ID].keys()][0]}.')\n",
    "\n",
    "    created = {}\n",
    "    if 'mgra_both' in input_list:\n",
    "        mgra_both = concat_dfs_temp(first_ID_unprocessed, second_ID_unprocessed)\n",
    "        created['mgra_both'] = mgra_both\n",
    "    if 'cpa_both' in input_list:\n",
    "        cpa_both = cpa_aggregation(first_ID_unprocessed, second_ID_unprocessed, cpa_level)\n",
    "        created['cpa_both'] = cpa_both\n",
    "    if 'jur_both' in input_list: \n",
    "        jur_both = jur_aggregation(first_ID_unprocessed, second_ID_unprocessed, jur_level)\n",
    "        created['jur_both'] = jur_both\n",
    "    if 'region_both' in input_list:\n",
    "        region_both = region_aggregation(first_ID_unprocessed, second_ID_unprocessed)\n",
    "        created['region_both'] = region_both\n",
    "    if 'mgra_diff' in input_list:\n",
    "        if 'mgra_both' not in input_list:\n",
    "            mgra_both = concat_dfs_temp(first_ID_unprocessed, second_ID_unprocessed)\n",
    "        mgra_diff = create_diff_temp(first_ID_features, second_ID_features, mgra_both)\n",
    "        created['mgra_diff'] = mgra_diff\n",
    "    if 'cpa_diff' in input_list:\n",
    "        if 'cpa_both' not in input_list:\n",
    "            cpa_both = cpa_aggregation(first_ID_unprocessed, second_ID_unprocessed, cpa_level)\n",
    "        cpa_diff = create_diff(first_ID_features, second_ID_features, cpa_both)\n",
    "        created['cpa_diff'] = cpa_diff\n",
    "    if 'jur_diff' in input_list:\n",
    "        if 'jur_both' not in input_list:\n",
    "            jur_both = jur_aggregation(first_ID_unprocessed, second_ID_unprocessed, jur_level)\n",
    "        jur_diff = create_diff(first_ID_features, second_ID_features, jur_both)\n",
    "        created['jur_diff'] = jur_diff\n",
    "    if 'region_diff' in input_list:\n",
    "        if 'region_both' not in input_list:\n",
    "            region_both = region_aggregation(first_ID_unprocessed, second_ID_unprocessed)\n",
    "        region_diff = create_diff(first_ID_features, second_ID_features, region_both)\n",
    "        created['region_diff'] = region_diff\n",
    "\n",
    "    generate_outputs(event, created)\n",
    "                            \n",
    "    print(f\"{first_ID} & {second_ID} {', '.join(created.keys())} outputs generated successfully!\")\n",
    "                            \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparison_window(output_path):\n",
    "    \"\"\"\n",
    "    Creates SimplePyGUI window that enables user to select multiple DS_ID's along with desired outputs. The window will\n",
    "    also have a console section where any output notes or errors will be displayed.\n",
    "    Returns click event as well as selected values (might remove return values since no purpose as of now).\n",
    "    \"\"\"\n",
    "    lb = sg.Listbox(values=comparison_selection_list, select_mode='multiple', size=(30, len(comparison_selection_list)+1), key='input_list')\n",
    "    \n",
    "    def select_all():\n",
    "        lb.set_value(comparison_selection_list)\n",
    "        return\n",
    "    def deselect_all():\n",
    "        lb.set_value([])\n",
    "        return\n",
    "    \n",
    "    layout_comparison = [\n",
    "        [sg.Button('Back', key='Back')],\n",
    "        [sg.Text('Please Select 2 DS_IDs')],\n",
    "        [sg.Listbox(values=(list(config.keys())[:-1]), select_mode='multiple', size=(30, len(config.keys())), key='DS_IDs')],\n",
    "        [sg.Text('Please Select Desired Outputs')],\n",
    "        [[sg.Button('Select All', target='input_list', key='select_all'), sg.Button('Clear All', target='input_list', key='clear_all')], lb],\n",
    "        [sg.Submit(key='comparison'), sg.Button('Cancel/Close', key='Cancel')],\n",
    "        [sg.Output(size=(100,20), key='output')]\n",
    "    ]\n",
    "    \n",
    "    window = sg.Window('Comparison window', layout_comparison, element_justification='c')\n",
    "    \n",
    "    while True: # Event Loop\n",
    "        event, values = window.Read()\n",
    "        if event in (None, 'Cancel', 'Back'):\n",
    "            break\n",
    "        if event == 'select_all':\n",
    "            select_all()\n",
    "        if event == 'clear_all':\n",
    "            deselect_all()\n",
    "        if event == 'comparison':\n",
    "            try:\n",
    "                output_notes = []\n",
    "                assert_inputs(event, values, output_path, output_notes)\n",
    "                print('Creating dataframes...')\n",
    "                create_comparison_dfs(event, first_ID, second_ID, values['input_list'], output_notes)\n",
    "                print()\n",
    "                print('\\n'.join(output_notes))\n",
    "                print()\n",
    "            except FileNotFoundError as f:\n",
    "                print('Please connect to the VPN. If connected, please check YML file datapaths.')\n",
    "            except Exception as e:\n",
    "                print(traceback.format_exc())\n",
    "            \n",
    "    window.Close()\n",
    "    window['output'].__del__()\n",
    "    \n",
    "    if event == 'Back':\n",
    "        initiate_window()\n",
    "    \n",
    "    return event, values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_individual_dfs(event, individual_IDs, input_list, output_notes):\n",
    "    \"\"\"\n",
    "    (Individual Only)\n",
    "    Function that runs through desired outputs and creates dataframes based on selected desired outputs. This function\n",
    "    also saves any notes that need to be displayed to the user.\n",
    "    \"\"\"\n",
    "    \n",
    "    for individual_ID in individual_IDs:\n",
    "        \n",
    "        globals()['individual_ID'] = individual_ID\n",
    "        \n",
    "        # download data for the ds_id\n",
    "        individual_ID_processed, individual_ID_unprocessed, individual_ID_features = download_DS_data(individual_ID, jur_level)\n",
    "\n",
    "        output_notes.append(f'Base year for {individual_ID} is {[item[-4:] for item in config[individual_ID].keys()][0]}.')\n",
    "\n",
    "        created = {}\n",
    "        if 'mgra_ind' in input_list:\n",
    "            mgra_ind = individual_ID_unprocessed.set_index('mgra')\n",
    "            created['mgra_ind'] = mgra_ind\n",
    "        if 'cpa_ind' in input_list:\n",
    "            cpa_ind = cpa_aggregation_ind(individual_ID_unprocessed, cpa_level)\n",
    "            created['cpa_ind'] = cpa_ind\n",
    "        if 'jur_ind' in input_list:\n",
    "            jur_ind = jur_aggregation_ind(individual_ID_unprocessed, jur_level)\n",
    "            created['jur_ind'] = jur_ind\n",
    "        if 'region_ind' in input_list:\n",
    "            region_ind = region_aggregation_ind(individual_ID_unprocessed)\n",
    "            created['region_ind'] = region_ind\n",
    "\n",
    "        generate_outputs(event, created)\n",
    "        print(f\"{individual_ID} {', '.join(created.keys())} outputs generated successfully!\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def individual_window(output_path):\n",
    "    \"\"\"\n",
    "    Creates SimplePyGUI window that enables user to select a single DS_ID along with desired outputs. The window will\n",
    "    also have a console section where any output notes or errors will be displayed.\n",
    "    Returns click event as well as selected values (might remove return values since no purpose as of now).\n",
    "    \"\"\"\n",
    "    lb_options = sg.Listbox(values=individual_selection_list, select_mode='multiple', size=(30, len(individual_selection_list)+1), key='input_list')\n",
    "    lb_ds = sg.Listbox(values=(list(config.keys())[:-1]), select_mode='multiple', size=(30, len(config.keys())), key='individual_ID')\n",
    "    \n",
    "    def select_all_options():\n",
    "        lb_options.set_value(individual_selection_list)\n",
    "        return\n",
    "    def deselect_all_options():\n",
    "        lb_options.set_value([])\n",
    "        return\n",
    "    \n",
    "    def select_all_ds():\n",
    "        lb_ds.set_value(list(config.keys())[:-1])\n",
    "        return\n",
    "    def deselect_all_ds():\n",
    "        lb_ds.set_value([])\n",
    "        return\n",
    "        \n",
    "    layout_individual = [\n",
    "        [sg.Button('Back', key='Back')],\n",
    "        [sg.Text('Please Select DS_ID(s)')],\n",
    "        [[sg.Button('Select All', target='individual_ID', key='select_all_ds'), sg.Button('Clear All', target='individual_ID', key='clear_all_ds')], lb_ds],\n",
    "        [sg.Text('Please Select Desired Outputs')],\n",
    "        [[sg.Button('Select All', target='input_list', key='select_all'), sg.Button('Clear All', target='input_list', key='clear_all')], lb_options],\n",
    "        [sg.Submit(key='individual'), sg.Button('Cancel/Close', key='Cancel')],\n",
    "        [sg.Output(size=(100,20), key='output')]\n",
    "    ]\n",
    "    \n",
    "    window = sg.Window('Individual window', layout_individual, element_justification='c')\n",
    "    \n",
    "    while True: # Event Loop\n",
    "        event, values = window.Read()\n",
    "        if event in (None, 'Cancel', 'Back'):\n",
    "            break\n",
    "        if event == 'select_all':\n",
    "            select_all_options()\n",
    "        if event == 'clear_all':\n",
    "            deselect_all_options()\n",
    "        if event == 'select_all_ds':\n",
    "            select_all_ds()\n",
    "        if event == 'clear_all_ds':\n",
    "            deselect_all_ds()\n",
    "        if event == 'individual':\n",
    "            try:\n",
    "                output_notes = []\n",
    "                assert_inputs(event, values, output_path, output_notes)\n",
    "                print('Creating dataframes...')\n",
    "                create_individual_dfs(event, values['individual_ID'], values['input_list'], output_notes)\n",
    "                print()\n",
    "                print('\\n'.join(output_notes))\n",
    "                print()\n",
    "            except FileNotFoundError as f:\n",
    "                print('Please connect to the VPN. If connected, please check YML file datapaths.')\n",
    "            except Exception as e:\n",
    "                print(traceback.format_exc())\n",
    "\n",
    "    window.Close()\n",
    "    window['output'].__del__()\n",
    "    \n",
    "    if event == 'Back':\n",
    "        initiate_window()\n",
    "    \n",
    "    return event, values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initiate_window():\n",
    "    \"\"\"\n",
    "    Function that initiates the window flow process starting with the base window. Helps coordinate transfer from base\n",
    "    window to either comparison or individual window based on click event returned from base window.\n",
    "    \"\"\"\n",
    "    sg.theme('SandyBeach')\n",
    "    \n",
    "    event, values = base_window()\n",
    "    output_path = values['output-path']\n",
    "    while True:\n",
    "        if event in [None, 'Cancel']:\n",
    "            return\n",
    "        if event == 'comparison-select':\n",
    "            event, values = comparison_window(output_path)\n",
    "            return\n",
    "        if event == 'individual-select':\n",
    "            event, values = individual_window(output_path)\n",
    "            return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "initiate_window()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO List:\n",
    "- Figure out what other output notes we need (especially for individual comparisons)\n",
    "- consider csv outputs as inputs to power bi\n",
    "\n",
    "\n",
    "- add mgra_id grouping for series 14 ds_ids (do we have csv files for series 14 we can test out? I think the ones we have been using are series 13.)\n",
    "- use outer join for the comparisons (**done but need to check if it works as intended**)\n",
    "- adjust sql query to be any series (currently queries only series 14 i think)\n",
    "\n",
    "series 14 mgra to jurisdiction: even if mgra falls into multiple juris, there are scenarios that one juridiction would report 0 to account for duplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IDEAS to consider:\n",
    "\n",
    "- should we rename columns based on sql tables (for clarity on column meanings)? **Already done for housing cols but maybe there's more we can do**\n",
    "- generate outputs to different folders for comparison or individual?\n",
    "- should we order the DS_ID's in the selection list?\n",
    "- should we always make diff tables newer - older? or older - newer? and we pick that by the DS_ID number right?\n",
    "- how are mgra csv files released? If there's a convention for folder file paths, maybe we could automate selection of new filepaths instead of using the yml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d60123f2ed8b63279fba5ddbefdeca593323e286d3975f7130d49323a9310301"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
