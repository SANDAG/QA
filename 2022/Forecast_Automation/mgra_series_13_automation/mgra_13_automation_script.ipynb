{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MGRA Series 13 Specific Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep track of runtime which will be printed at the end of this notebook\n",
    "import time\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "import pathlib\n",
    "\n",
    "import pandas as pd\n",
    "import sqlalchemy as sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters and Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "DDAM = sql.create_engine('mssql+pymssql://DDAMWSQL16/')\n",
    "\n",
    "# Where to save outputs and the file format to save as\n",
    "SAVE_FOLDER = pathlib.Path(\"./mgra_13_outputs/\")\n",
    "FILE_TEMPLATE = \"forecast_{dsid}_{table}.csv\"\n",
    "\n",
    "# TODO\n",
    "GEOGRAPHIES = [\"mgra_id\", \"mgra\", \"cpa\", \"jurisdiction\", \"region\"]\n",
    "FORMATTED_GEOS = f\"mgra.{', '.join(GEOGRAPHIES)}\"\n",
    "\n",
    "# TODO\n",
    "MGRA_SERIES = 14\n",
    "DATASOURCE_IDS = [35, 38, 41, 42]\n",
    "\n",
    "# TODO\n",
    "category_queries = {\n",
    "    \"age\": textwrap.dedent(\"\"\"\\\n",
    "        SELECT DISTINCT name\n",
    "        FROM [demographic_warehouse].[dim].[age_group]\n",
    "        ORDER BY name\n",
    "        \"\"\"),\n",
    "    \"ethnicity\": textwrap.dedent(\"\"\"\\\n",
    "        SELECT DISTINCT long_name\n",
    "        FROM [demographic_warehouse].[dim].[ethnicity]\n",
    "        ORDER BY long_name\n",
    "        \"\"\"),\n",
    "    \"household_income\": textwrap.dedent(\"\"\"\\\n",
    "        SELECT DISTINCT name\n",
    "        FROM [demographic_warehouse].[dim].[income_group]\n",
    "        WHERE categorization = 10\n",
    "            AND constant_dollars_year = 2010\n",
    "        \"\"\"),\n",
    "    \"housing\": textwrap.dedent(\"\"\"\\\n",
    "        SELECT DISTINCT long_name\n",
    "        FROM [demographic_warehouse].[dim].[structure_type]\n",
    "        ORDER BY long_name\n",
    "        \"\"\"),\n",
    "    \"jobs\": textwrap.dedent(\"\"\"\\\n",
    "        SELECT DISTINCT full_name\n",
    "        FROM [demographic_warehouse].[dim].[employment_type]\n",
    "        ORDER BY full_name\n",
    "        \"\"\"),\n",
    "    \"population\":textwrap.dedent(\"\"\"\\\n",
    "        SELECT DISTINCT long_name\n",
    "        FROM [demographic_warehouse].[dim].[housing_type]\n",
    "        ORDER BY long_name\n",
    "        \"\"\"),\n",
    "    \"sex\": textwrap.dedent(\"\"\"\\\n",
    "        SELECT DISTINCT sex\n",
    "        FROM [demographic_warehouse].[dim].[sex]\n",
    "        ORDER BY sex\n",
    "        \"\"\"),\n",
    "}\n",
    "\n",
    "# TODO\n",
    "fact_queries = {\n",
    "    \"age\": textwrap.dedent(\"\"\"\\\n",
    "        SELECT * FROM (\n",
    "            SELECT {geos}, yr_id, age_group.[name], [population] \n",
    "            FROM [demographic_warehouse].[fact].[age] as tbl\n",
    "            INNER JOIN [demographic_warehouse].[dim].[mgra_denormalize] AS mgra\n",
    "                ON mgra.mgra_id = tbl.mgra_id\n",
    "                AND mgra.series = {mgra_series}\n",
    "            INNER JOIN [demographic_warehouse].[dim].[age_group] as age_group\n",
    "                ON age_group.age_group_id = tbl.age_group_id\n",
    "            WHERE tbl.datasource_id = {dsid}) as p\n",
    "        PIVOT (\n",
    "            SUM([population])\n",
    "            FOR [name] IN (\n",
    "                {categories}\n",
    "            )\n",
    "        ) as pivot_table\n",
    "        ORDER BY mgra_id, yr_id\n",
    "        \"\"\"),\n",
    "    \"ethnicity\": textwrap.dedent(\"\"\"\\\n",
    "        SELECT * FROM (\n",
    "            SELECT {geos}, yr_id, ethnicity.[long_name], [population] \n",
    "            FROM [demographic_warehouse].[fact].[ethnicity] as tbl\n",
    "            INNER JOIN [demographic_warehouse].[dim].[mgra_denormalize] AS mgra\n",
    "                ON mgra.mgra_id = tbl.mgra_id\n",
    "                AND mgra.series = {mgra_series}\n",
    "            INNER JOIN [demographic_warehouse].[dim].[ethnicity] as ethnicity\n",
    "                ON ethnicity.ethnicity_id = tbl.ethnicity_id\n",
    "            WHERE tbl.datasource_id = {dsid}) as p\n",
    "        PIVOT (\n",
    "            SUM([population])\n",
    "            FOR [long_name] IN (\n",
    "                {categories}\n",
    "            )\n",
    "        ) as pivot_table\n",
    "        ORDER BY mgra_id, yr_id\n",
    "        \"\"\"),\n",
    "    \"household_income\": textwrap.dedent(\"\"\"\\\n",
    "        SELECT * FROM (\n",
    "            SELECT {geos}, yr_id, income_group.[name], [households] \n",
    "            FROM [demographic_warehouse].[fact].[household_income] as tbl\n",
    "            INNER JOIN [demographic_warehouse].[dim].[mgra_denormalize] AS mgra\n",
    "                ON mgra.mgra_id = tbl.mgra_id\n",
    "                AND mgra.series = {mgra_series}\n",
    "            INNER JOIN [demographic_warehouse].[dim].[income_group] as income_group\n",
    "                ON income_group.income_group_id = tbl.income_group_id\n",
    "            WHERE tbl.datasource_id = {dsid}) as p\n",
    "        PIVOT (\n",
    "            SUM([households])\n",
    "            FOR [name] IN (\n",
    "                {categories}\n",
    "            )\n",
    "        ) as pivot_table\n",
    "        ORDER BY mgra_id, yr_id\n",
    "        \"\"\"),\n",
    "    \"housing\": textwrap.dedent(\"\"\"\\\n",
    "        SELECT * FROM (\n",
    "            SELECT {geos}, yr_id, structure_type.[long_name], [units] \n",
    "            FROM [demographic_warehouse].[fact].[housing] as tbl\n",
    "            INNER JOIN [demographic_warehouse].[dim].[mgra_denormalize] AS mgra\n",
    "                ON mgra.mgra_id = tbl.mgra_id\n",
    "                AND mgra.series = {mgra_series}\n",
    "            INNER JOIN [demographic_warehouse].[dim].[structure_type] as structure_type\n",
    "                ON structure_type.structure_type_id = tbl.structure_type_id\n",
    "            WHERE tbl.datasource_id = {dsid}) as p\n",
    "        PIVOT (\n",
    "            SUM([units])\n",
    "            FOR [long_name] IN (\n",
    "                {categories}\n",
    "            )\n",
    "        ) as pivot_table\n",
    "        ORDER BY mgra_id, yr_id\n",
    "        \"\"\"),\n",
    "    \"housing_units\": textwrap.dedent(\"\"\"\\\n",
    "        SELECT {geos}, yr_id, \n",
    "            SUM([units]) as units, \n",
    "            SUM([unoccupiable]) as unoccupiable, \n",
    "            SUM([occupied]) as occupied, \n",
    "            SUM([vacancy]) as vacancy\n",
    "        FROM [demographic_warehouse].[fact].[housing] as tbl\n",
    "        INNER JOIN [demographic_warehouse].[dim].[mgra_denormalize] AS mgra\n",
    "            ON mgra.mgra_id = tbl.mgra_id\n",
    "            AND mgra.series = {mgra_series}\n",
    "        WHERE tbl.datasource_id = {dsid}\n",
    "        GROUP BY {geos}, yr_id\n",
    "        ORDER BY {geos}, yr_id\n",
    "        \"\"\"),\n",
    "    \"jobs\": textwrap.dedent(\"\"\"\\\n",
    "        SELECT * FROM (\n",
    "            SELECT {geos}, yr_id, employment_type.[full_name], [jobs] \n",
    "            FROM [demographic_warehouse].[fact].[jobs] as tbl\n",
    "            INNER JOIN [demographic_warehouse].[dim].[mgra_denormalize] AS mgra\n",
    "                ON mgra.mgra_id = tbl.mgra_id\n",
    "                AND mgra.series = {mgra_series}\n",
    "            INNER JOIN [demographic_warehouse].[dim].[employment_type] as employment_type\n",
    "                ON employment_type.employment_type_id = tbl.employment_type_id\n",
    "            WHERE tbl.datasource_id = {dsid}) as p\n",
    "        PIVOT (\n",
    "            SUM([jobs])\n",
    "            FOR [full_name] IN (\n",
    "                {categories}\n",
    "            )\n",
    "        ) as pivot_table\n",
    "        ORDER BY mgra_id, yr_id\n",
    "        \"\"\"),\n",
    "    \"population\":textwrap.dedent(\"\"\"\\\n",
    "        SELECT * FROM (\n",
    "            SELECT {geos}, yr_id, housing_type.[long_name], [population] \n",
    "            FROM [demographic_warehouse].[fact].[population] as tbl\n",
    "            INNER JOIN [demographic_warehouse].[dim].[mgra_denormalize] AS mgra\n",
    "                ON mgra.mgra_id = tbl.mgra_id\n",
    "                AND mgra.series = {mgra_series}\n",
    "            INNER JOIN [demographic_warehouse].[dim].[housing_type] as housing_type\n",
    "                ON housing_type.housing_type_id = tbl.housing_type_id\n",
    "            WHERE tbl.datasource_id = {dsid}) as p\n",
    "        PIVOT (\n",
    "            SUM([population])\n",
    "            FOR [long_name] IN (\n",
    "                {categories}\n",
    "            )\n",
    "        ) as pivot_table\n",
    "        ORDER BY mgra_id, yr_id\n",
    "        \"\"\"),\n",
    "    \"sex\": textwrap.dedent(\"\"\"\\\n",
    "        SELECT * FROM (\n",
    "            SELECT {geos}, yr_id, sex.[sex], [population] \n",
    "            FROM [demographic_warehouse].[fact].[sex] as tbl\n",
    "            INNER JOIN [demographic_warehouse].[dim].[mgra_denormalize] AS mgra\n",
    "                ON mgra.mgra_id = tbl.mgra_id\n",
    "                AND mgra.series = {mgra_series}\n",
    "            INNER JOIN [demographic_warehouse].[dim].[sex] as sex\n",
    "                ON sex.sex_id = tbl.sex_id\n",
    "            WHERE tbl.datasource_id = {dsid}) as p\n",
    "        PIVOT (\n",
    "            SUM([population])\n",
    "            FOR [sex] IN (\n",
    "                {categories}\n",
    "            )\n",
    "        ) as pivot_table\n",
    "        ORDER BY mgra_id, yr_id\n",
    "        \"\"\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting datasource_id=35, table=age\n",
      "File already exists, skipping...\n",
      "\n",
      "Getting datasource_id=35, table=ethnicity\n",
      "File already exists, skipping...\n",
      "\n",
      "Getting datasource_id=35, table=household_income\n",
      "File already exists, skipping...\n",
      "\n",
      "Getting datasource_id=35, table=housing\n",
      "File already exists, skipping...\n",
      "\n",
      "Getting datasource_id=35, table=housing_units\n",
      "File already exists, skipping...\n",
      "\n",
      "Getting datasource_id=35, table=jobs\n",
      "File already exists, skipping...\n",
      "\n",
      "Getting datasource_id=35, table=population\n",
      "File already exists, skipping...\n",
      "\n",
      "Getting datasource_id=35, table=sex\n",
      "File already exists, skipping...\n",
      "\n",
      "Getting datasource_id=38, table=age\n",
      "File already exists, skipping...\n",
      "\n",
      "Getting datasource_id=38, table=ethnicity\n",
      "File already exists, skipping...\n",
      "\n",
      "Getting datasource_id=38, table=household_income\n",
      "File already exists, skipping...\n",
      "\n",
      "Getting datasource_id=38, table=housing\n",
      "File already exists, skipping...\n",
      "\n",
      "Getting datasource_id=38, table=housing_units\n",
      "File already exists, skipping...\n",
      "\n",
      "Getting datasource_id=38, table=jobs\n",
      "File already exists, skipping...\n",
      "\n",
      "Getting datasource_id=38, table=population\n",
      "File already exists, skipping...\n",
      "\n",
      "Getting datasource_id=38, table=sex\n",
      "File already exists, skipping...\n",
      "\n",
      "Getting datasource_id=41, table=age\n",
      "File already exists, skipping...\n",
      "\n",
      "Getting datasource_id=41, table=ethnicity\n",
      "File already exists, skipping...\n",
      "\n",
      "Getting datasource_id=41, table=household_income\n",
      "File already exists, skipping...\n",
      "\n",
      "Getting datasource_id=41, table=housing\n",
      "File already exists, skipping...\n",
      "\n",
      "Getting datasource_id=41, table=housing_units\n",
      "File already exists, skipping...\n",
      "\n",
      "Getting datasource_id=41, table=jobs\n",
      "File already exists, skipping...\n",
      "\n",
      "Getting datasource_id=41, table=population\n",
      "File already exists, skipping...\n",
      "\n",
      "Getting datasource_id=41, table=sex\n",
      "File already exists, skipping...\n",
      "\n",
      "Getting datasource_id=42, table=age\n",
      "File already exists, skipping...\n",
      "\n",
      "Getting datasource_id=42, table=ethnicity\n",
      "File already exists, skipping...\n",
      "\n",
      "Getting datasource_id=42, table=household_income\n",
      "File already exists, skipping...\n",
      "\n",
      "Getting datasource_id=42, table=housing\n",
      "File already exists, skipping...\n",
      "\n",
      "Getting datasource_id=42, table=housing_units\n",
      "File already exists, skipping...\n",
      "\n",
      "Getting datasource_id=42, table=jobs\n",
      "File already exists, skipping...\n",
      "\n",
      "Getting datasource_id=42, table=population\n",
      "File already exists, skipping...\n",
      "\n",
      "Getting datasource_id=42, table=sex\n",
      "File already exists, skipping...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for datasource_id in DATASOURCE_IDS:\n",
    "    for table_name, query in fact_queries.items():\n",
    "\n",
    "        # Get and save the file\n",
    "        print(f\"Getting datasource_id={datasource_id}, table={table_name}\")\n",
    "\n",
    "        # Skip the file if it exists already\n",
    "        file_name = SAVE_FOLDER / FILE_TEMPLATE.format(dsid=datasource_id, table=table_name)\n",
    "        if(file_name.is_file()):\n",
    "            print(\"File already exists, skipping...\")\n",
    "            \n",
    "        # If the file does not exist than download and save\n",
    "        else:\n",
    "            print(\"Getting table from DDAMWSQL16\")\n",
    "\n",
    "            # The housing units table is already in pivot table format, no need to get the \n",
    "            # categorical variables\n",
    "            if(table_name != \"housing_units\"):\n",
    "\n",
    "                # Get the list of categorical variables\n",
    "                cat_vars = [f\"[{x[0]}]\" for x in pd.read_sql_query(category_queries[table_name], con=DDAM).values]\n",
    "                cat_vars = \", \".join(cat_vars)\n",
    "\n",
    "                # Format the query\n",
    "                formatted_query = query.format(\n",
    "                    geos=FORMATTED_GEOS, \n",
    "                    mgra_series=MGRA_SERIES, \n",
    "                    dsid=datasource_id,\n",
    "                    categories=cat_vars)\n",
    "                \n",
    "                # Actually get and save the file\n",
    "                table = pd.read_sql_query(formatted_query, con=DDAM)\n",
    "                \n",
    "                # The jobs table contains a bunch of extra years, remove them\n",
    "                if(table_name == \"jobs\"):\n",
    "                    years = pd.read_sql_query(textwrap.dedent(\"\"\"\\\n",
    "                        SELECT DISTINCT yr_id\n",
    "                        FROM [demographic_warehouse].[fact].[age]\n",
    "                        WHERE datasource_id = 41\n",
    "                        \"\"\"), con=DDAM)\n",
    "                    table = table[table[\"yr_id\"].isin(years[\"yr_id\"])]\n",
    "                table.to_csv(file_name, index=False)\n",
    "            \n",
    "            else:\n",
    "                # Custom behavior for the housing units table\n",
    "                formatted_query = query.format(\n",
    "                    geos=FORMATTED_GEOS, \n",
    "                    mgra_series=MGRA_SERIES, \n",
    "                    dsid=datasource_id)\n",
    "                table = pd.read_sql_query(formatted_query, con=DDAM)\n",
    "                table.to_csv(file_name, index=False)\n",
    "\n",
    "            print(\"Completed\")\n",
    "            \n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verifying the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the files in the save folder\n",
    "files = [f for f in SAVE_FOLDER.glob(\"**/*\") if f.is_file()]\n",
    "\n",
    "# It is possible that consolidated files already exist in the folder, so filter out any files\n",
    "# which contain the string \"ind\"\n",
    "files = [f for f in files if \"ind\" not in str(f)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking mgra_13_outputs\\forecast_35_age.csv\n",
      "No Errors\n",
      "\n",
      "Checking mgra_13_outputs\\forecast_35_ethnicity.csv\n",
      "No Errors\n",
      "\n",
      "Checking mgra_13_outputs\\forecast_35_household_income.csv\n",
      "No Errors\n",
      "\n",
      "Checking mgra_13_outputs\\forecast_35_housing.csv\n",
      "No Errors\n",
      "\n",
      "Checking mgra_13_outputs\\forecast_35_housing_units.csv\n",
      "No Errors\n",
      "\n",
      "Checking mgra_13_outputs\\forecast_35_jobs.csv\n",
      "No Errors\n",
      "\n",
      "Checking mgra_13_outputs\\forecast_35_population.csv\n",
      "No Errors\n",
      "\n",
      "Checking mgra_13_outputs\\forecast_35_sex.csv\n",
      "No Errors\n",
      "\n",
      "Checking mgra_13_outputs\\forecast_38_age.csv\n",
      "No Errors\n",
      "\n",
      "Checking mgra_13_outputs\\forecast_38_ethnicity.csv\n",
      "No Errors\n",
      "\n",
      "Checking mgra_13_outputs\\forecast_38_household_income.csv\n",
      "No Errors\n",
      "\n",
      "Checking mgra_13_outputs\\forecast_38_housing.csv\n",
      "No Errors\n",
      "\n",
      "Checking mgra_13_outputs\\forecast_38_housing_units.csv\n",
      "No Errors\n",
      "\n",
      "Checking mgra_13_outputs\\forecast_38_jobs.csv\n",
      "No Errors\n",
      "\n",
      "Checking mgra_13_outputs\\forecast_38_population.csv\n",
      "No Errors\n",
      "\n",
      "Checking mgra_13_outputs\\forecast_38_sex.csv\n",
      "No Errors\n",
      "\n",
      "Checking mgra_13_outputs\\forecast_41_age.csv\n",
      "No Errors\n",
      "\n",
      "Checking mgra_13_outputs\\forecast_41_ethnicity.csv\n",
      "No Errors\n",
      "\n",
      "Checking mgra_13_outputs\\forecast_41_household_income.csv\n",
      "No Errors\n",
      "\n",
      "Checking mgra_13_outputs\\forecast_41_housing.csv\n",
      "No Errors\n",
      "\n",
      "Checking mgra_13_outputs\\forecast_41_housing_units.csv\n",
      "No Errors\n",
      "\n",
      "Checking mgra_13_outputs\\forecast_41_jobs.csv\n",
      "No Errors\n",
      "\n",
      "Checking mgra_13_outputs\\forecast_41_population.csv\n",
      "No Errors\n",
      "\n",
      "Checking mgra_13_outputs\\forecast_41_sex.csv\n",
      "No Errors\n",
      "\n",
      "Checking mgra_13_outputs\\forecast_42_age.csv\n",
      "No Errors\n",
      "\n",
      "Checking mgra_13_outputs\\forecast_42_ethnicity.csv\n",
      "No Errors\n",
      "\n",
      "Checking mgra_13_outputs\\forecast_42_household_income.csv\n",
      "No Errors\n",
      "\n",
      "Checking mgra_13_outputs\\forecast_42_housing.csv\n",
      "No Errors\n",
      "\n",
      "Checking mgra_13_outputs\\forecast_42_housing_units.csv\n",
      "No Errors\n",
      "\n",
      "Checking mgra_13_outputs\\forecast_42_jobs.csv\n",
      "No Errors\n",
      "\n",
      "Checking mgra_13_outputs\\forecast_42_population.csv\n",
      "No Errors\n",
      "\n",
      "Checking mgra_13_outputs\\forecast_42_sex.csv\n",
      "No Errors\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check that within each file...\n",
    "for file in files:\n",
    "    print(f\"Checking {file}\")\n",
    "    table = pd.read_csv(file)\n",
    "    errors = False\n",
    "\n",
    "    # Each mgra_id is associated with each year. In other words, the number of rows should be the \n",
    "    # number of distinct mgra_ids multiplied by the number of distinct yr_ids\n",
    "    num_mgra_id = len(table[\"mgra_id\"].unique())\n",
    "    num_yr_id = len(table[\"yr_id\"].unique())\n",
    "    if(num_mgra_id * num_yr_id != table.shape[0]):\n",
    "        errors = True\n",
    "        print(textwrap.dedent(f\"\"\"\\\n",
    "            {file} has {num_mgra_id} distinct mgra_ids and {num_yr_id} distinct num_yr_ids, so it \n",
    "            should have {num_mgra_id} x {num_yr_id} = {num_mgra_id * num_yr_id} rows of data. \n",
    "            However, {file} only has {table.shape[0]} rows of data.\n",
    "            \"\"\").replace(\"\\n\", \"\").replace(\"\\r\", \"\"))\n",
    "\n",
    "    # Each unique mgra_id appears in num_yr_id rows of data, and each unique yr_id appears in \n",
    "    # num_mgra_id rows of data\n",
    "    count = (table[\"mgra_id\"].value_counts() == num_yr_id).sum()\n",
    "    if(not count == num_mgra_id):\n",
    "        errors = True\n",
    "        print(textwrap.dedent(f\"\"\"\\\n",
    "            Each unique mgra_id should appear once for each distinct year, or {num_yr_id} times. \n",
    "            However, this only occurs for {count} mgra_ids instead of {num_mgra_id} mgra_ids.\n",
    "            \"\"\").replace(\"\\n\", \"\"))\n",
    "    count = (table[\"yr_id\"].value_counts() == num_mgra_id).sum()\n",
    "    if(not count == num_yr_id):\n",
    "        errors = True\n",
    "        print(textwrap.dedent(f\"\"\"\\\n",
    "            Each unique yr_id should appear once for each distinct mgra_id, or {num_mgra_id} times. \n",
    "            However, this only occurs for {count} yr_ids instead of {num_yr_id} yr_ids.\n",
    "            \"\"\").replace(\"\\n\", \"\"))\n",
    "\n",
    "    # Note the lack of errors if necessary\n",
    "    if(not errors):\n",
    "        print(\"No Errors\")\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consolidating the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the files for each datasource\n",
    "for datasource_id in DATASOURCE_IDS:\n",
    "    ds_files = [f for f in files if str(datasource_id) in str(f)]\n",
    "\n",
    "    # Get the tables\n",
    "    tables = []\n",
    "    for file in ds_files:\n",
    "        tables.append(pd.read_csv(file))\n",
    "\n",
    "    consolidated = tables[0]\n",
    "    for i in range(1, len(tables)):\n",
    "        consolidated = pd.concat([consolidated, tables[i].drop(GEOGRAPHIES + [\"yr_id\"], axis=1)], axis=1)\n",
    "\n",
    "    consolidated.to_csv(SAVE_FOLDER / f\"forecast_{datasource_id}_mgra_id_ind.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating from mgra_id to mgra, cpa, jurisdiction, region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregating forecast 35 from \"mgra_id\" to mgra, cpa, jurisdiction, region\n",
      "Completed\n",
      "\n",
      "Aggregating forecast 38 from \"mgra_id\" to mgra, cpa, jurisdiction, region\n",
      "Completed\n",
      "\n",
      "Aggregating forecast 41 from \"mgra_id\" to mgra, cpa, jurisdiction, region\n",
      "Completed\n",
      "\n",
      "Aggregating forecast 42 from \"mgra_id\" to mgra, cpa, jurisdiction, region\n",
      "Completed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the consolidated file for each datasource\n",
    "for datasource_id in DATASOURCE_IDS:\n",
    "    consolidated = pd.read_csv(SAVE_FOLDER / f\"forecast_{datasource_id}_mgra_id_ind.csv\")\n",
    "\n",
    "    # Aggregate up to every level except mgra_id\n",
    "    aggregate_geo_list = GEOGRAPHIES[:]\n",
    "    aggregate_geo_list.remove(\"mgra_id\")\n",
    "\n",
    "    print(f\"Aggregating forecast {datasource_id} from \\\"mgra_id\\\" to {', '.join(aggregate_geo_list)}\")\n",
    "\n",
    "    # Aggregate up to each geography level\n",
    "    for agg_geo in aggregate_geo_list:\n",
    "\n",
    "        # First select the columns which have actual data\n",
    "        # NOTE: This includes \"yr_id\"\n",
    "        data_cols = list(consolidated.columns[len(GEOGRAPHIES):])\n",
    "\n",
    "        # Then filter to only the geography we want and those data columns\n",
    "        aggregated = consolidated.copy(deep=True)[[agg_geo] + data_cols]\n",
    "\n",
    "        # Finally group by the geography and year\n",
    "        aggregated = aggregated.groupby([agg_geo, \"yr_id\"]).sum().reset_index(drop=False)\n",
    "\n",
    "        # Save the aggregated file with an appropriate name\n",
    "        aggregated.to_csv(SAVE_FOLDER / f\"forecast_{datasource_id}_{agg_geo}_ind.csv\", index=False)\n",
    "\n",
    "    print(\"Completed\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime: 1 minutes, 3 seconds\n"
     ]
    }
   ],
   "source": [
    "runtime = time.time() - start\n",
    "minutes, seconds = divmod(runtime, 60)\n",
    "print(f'Runtime: {int(minutes)} minutes, {(int(seconds))} seconds')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7804eeadc717885dfaa8f49b012a5fe9d8355528c06deeb48f3c48c16fd8060a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
