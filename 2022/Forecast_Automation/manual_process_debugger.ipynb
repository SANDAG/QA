{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging Script \n",
    "This is a manual script of the functions for debugging purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#Libraries \n",
    "import os\n",
    "import pyodbc\n",
    "import glob\n",
    "import copy\n",
    "import PySimpleGUI as sg\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bring in Part 1 Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install -r ./config_files/requirements.txt\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "('08001', '[08001] [Microsoft][ODBC Driver 17 for SQL Server]Named Pipes Provider: Could not open a connection to SQL Server [53].  (53) (SQLDriverConnect); [08001] [Microsoft][ODBC Driver 17 for SQL Server]Login timeout expired (0); [08001] [Microsoft][ODBC Driver 17 for SQL Server]A network-related or instance-specific error has occurred while establishing a connection to SQL Server. Server is not found or not accessible. Check if instance name is correct and if SQL Server is configured to allow remote connections. For more information see SQL Server Books Online. (53)')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_29688\\1393446941.py:1\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m conn \u001b[39m=\u001b[39m pyodbc\u001b[39m.\u001b[39;49mconnect(\u001b[39m'\u001b[39;49m\u001b[39mDriver=\u001b[39;49m\u001b[39m{\u001b[39;49m\u001b[39mODBC Driver 17 for SQL Server};\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[0;32m      2\u001b[0m                       \u001b[39m'\u001b[39;49m\u001b[39mServer=DDAMWSQL16.sandag.org;\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[0;32m      3\u001b[0m                       \u001b[39m'\u001b[39;49m\u001b[39mDatabase=demographic_warehouse;\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[0;32m      4\u001b[0m                       \u001b[39m'\u001b[39;49m\u001b[39mTrusted_Connection=yes;\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[1;31mOperationalError\u001b[0m: ('08001', '[08001] [Microsoft][ODBC Driver 17 for SQL Server]Named Pipes Provider: Could not open a connection to SQL Server [53].  (53) (SQLDriverConnect); [08001] [Microsoft][ODBC Driver 17 for SQL Server]Login timeout expired (0); [08001] [Microsoft][ODBC Driver 17 for SQL Server]A network-related or instance-specific error has occurred while establishing a connection to SQL Server. Server is not found or not accessible. Check if instance name is correct and if SQL Server is configured to allow remote connections. For more information see SQL Server Books Online. (53)')"
     ]
    },
    {
     "ename": "OperationalError",
     "evalue": "('08001', '[08001] [Microsoft][ODBC Driver 17 for SQL Server]Named Pipes Provider: Could not open a connection to SQL Server [53].  (53) (SQLDriverConnect); [08001] [Microsoft][ODBC Driver 17 for SQL Server]Login timeout expired (0); [08001] [Microsoft][ODBC Driver 17 for SQL Server]A network-related or instance-specific error has occurred while establishing a connection to SQL Server. Server is not found or not accessible. Check if instance name is correct and if SQL Server is configured to allow remote connections. For more information see SQL Server Books Online. (53)')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\cra\\OneDrive - San Diego Association of Governments\\QA_Repository\\2022\\Forecast_Automation\\manual_process_debugger.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/cra/OneDrive%20-%20San%20Diego%20Association%20of%20Governments/QA_Repository/2022/Forecast_Automation/manual_process_debugger.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Bring in functions\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/cra/OneDrive%20-%20San%20Diego%20Association%20of%20Governments/QA_Repository/2022/Forecast_Automation/manual_process_debugger.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m get_ipython()\u001b[39m.\u001b[39;49mrun_line_magic(\u001b[39m'\u001b[39;49m\u001b[39mrun\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m./scripts/Part_1.ipynb\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\cra\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2285\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[1;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[0;32m   2283\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mlocal_ns\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_local_scope(stack_depth)\n\u001b[0;32m   2284\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuiltin_trap:\n\u001b[1;32m-> 2285\u001b[0m     result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   2286\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\cra\\Anaconda3\\lib\\site-packages\\IPython\\core\\magics\\execution.py:717\u001b[0m, in \u001b[0;36mExecutionMagics.run\u001b[1;34m(self, parameter_s, runner, file_finder)\u001b[0m\n\u001b[0;32m    715\u001b[0m     \u001b[39mwith\u001b[39;00m preserve_keys(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshell\u001b[39m.\u001b[39muser_ns, \u001b[39m'\u001b[39m\u001b[39m__file__\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    716\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshell\u001b[39m.\u001b[39muser_ns[\u001b[39m'\u001b[39m\u001b[39m__file__\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m filename\n\u001b[1;32m--> 717\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshell\u001b[39m.\u001b[39;49msafe_execfile_ipy(filename, raise_exceptions\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    718\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    720\u001b[0m \u001b[39m# Control the response to exit() calls made by the script being run\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\cra\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2791\u001b[0m, in \u001b[0;36mInteractiveShell.safe_execfile_ipy\u001b[1;34m(self, fname, shell_futures, raise_exceptions)\u001b[0m\n\u001b[0;32m   2789\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_cell(cell, silent\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, shell_futures\u001b[39m=\u001b[39mshell_futures)\n\u001b[0;32m   2790\u001b[0m \u001b[39mif\u001b[39;00m raise_exceptions:\n\u001b[1;32m-> 2791\u001b[0m     result\u001b[39m.\u001b[39;49mraise_error()\n\u001b[0;32m   2792\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m result\u001b[39m.\u001b[39msuccess:\n\u001b[0;32m   2793\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\cra\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:240\u001b[0m, in \u001b[0;36mExecutionResult.raise_error\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    238\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39merror_before_exec\n\u001b[0;32m    239\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39merror_in_exec \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 240\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39merror_in_exec\n",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_29688\\1393446941.py:1\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m conn \u001b[39m=\u001b[39m pyodbc\u001b[39m.\u001b[39;49mconnect(\u001b[39m'\u001b[39;49m\u001b[39mDriver=\u001b[39;49m\u001b[39m{\u001b[39;49m\u001b[39mODBC Driver 17 for SQL Server};\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[0;32m      2\u001b[0m                       \u001b[39m'\u001b[39;49m\u001b[39mServer=DDAMWSQL16.sandag.org;\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[0;32m      3\u001b[0m                       \u001b[39m'\u001b[39;49m\u001b[39mDatabase=demographic_warehouse;\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[0;32m      4\u001b[0m                       \u001b[39m'\u001b[39;49m\u001b[39mTrusted_Connection=yes;\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[1;31mOperationalError\u001b[0m: ('08001', '[08001] [Microsoft][ODBC Driver 17 for SQL Server]Named Pipes Provider: Could not open a connection to SQL Server [53].  (53) (SQLDriverConnect); [08001] [Microsoft][ODBC Driver 17 for SQL Server]Login timeout expired (0); [08001] [Microsoft][ODBC Driver 17 for SQL Server]A network-related or instance-specific error has occurred while establishing a connection to SQL Server. Server is not found or not accessible. Check if instance name is correct and if SQL Server is configured to allow remote connections. For more information see SQL Server Books Online. (53)')"
     ]
    }
   ],
   "source": [
    "# Bring in functions\n",
    "%run ./scripts/Part_1.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Individual Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs \n",
    "ds_ID = 'DS42'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "comparison_processed_data vs comparison_no_geozone_df:\n",
    "- comparison_processed_data has columns appending the DSID and has the geozone at the end (jurisdiction level)\n",
    "- features are all of teh columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DS42's jurisdiction did not merge correctly.\n"
     ]
    }
   ],
   "source": [
    "# mgra_ind\n",
    "comparison_processed_data, comparison_no_geozone_df, features = download_DS_data(ds_ID, jur_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPA Level Aggregation\n",
    "comparison_processed_data_cpa = cpa_aggregation_ind(comparison_no_geozone_df, cpa_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jurisdiction aggregation\n",
    "comparison_processed_data_jur = jur_aggregation_ind(comparison_no_geozone_df, jur_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Region Aggregation\n",
    "comparison_processed_data_reg = region_aggregation_ind(comparison_no_geozone_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs for comparison \n",
    "first_ID = \"DS38\"\n",
    "second_ID = 'DS41'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DS38's jurisdiction did not merge correctly.\n",
      "DS41's jurisdiction did not merge correctly.\n"
     ]
    }
   ],
   "source": [
    "# Download the necessary data\n",
    "# First ID\n",
    "comparison_first_ID_processed_data, comparison_first_ID_no_geozone_df, first_ID_features = download_DS_data(first_ID, jur_level)\n",
    "\n",
    "# Second ID\n",
    "comparison_second_ID_processed_data, comparison_second_ID_no_geozone_df, second_ID_features = download_DS_data(second_ID, jur_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Both Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MGRA_Both Files\n",
    "# This does the right thing and drops 'secondary' not sure how it knows to do that but it does \n",
    "mgra_both = concat_dfs_temp(comparison_first_ID_no_geozone_df, comparison_second_ID_no_geozone_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPA both\n",
    "cpa_both = cpa_aggregation(comparison_first_ID_no_geozone_df, comparison_second_ID_no_geozone_df, cpa_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jur both \n",
    "jur_both = jur_aggregation(comparison_first_ID_no_geozone_df, comparison_second_ID_no_geozone_df, jur_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Region Both\n",
    "region_both = region_aggregation(comparison_first_ID_no_geozone_df, comparison_second_ID_no_geozone_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diff Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cra\\AppData\\Local\\Temp\\ipykernel_20132\\564207998.py:16: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  diff_df[f'{column}_diff'] = first_second_ID_comparison[f'{column}_{first_ID}'] - first_second_ID_comparison[f'{column}_{second_ID}']\n"
     ]
    }
   ],
   "source": [
    "'''The issue is that in mgra_both 'secondary' does not exist '''\n",
    "\n",
    "'''The issue with this code originally is that the input originally was create_diff(features_first_ID, features_second_ID, first_second_ID_comparison) and the features_first_ID had non numeric columns such as secondary and elementary while mgra-both only had numeric (because of the groupby at the end) so the way the code was written it was trying to subtract columns that were alike in 'features_first_ID' and 'features_second_ID' but some didn't exist in mgra_both'''\n",
    "\n",
    "'''Create diff goes and keeps things in the same order, it doesn't use set. Now the code is grabbing columns from the both file itself. '''\n",
    "\n",
    "mgra_diff = create_diff(list([x[:-5] for x in mgra_both if x[-5:] == '_' + first_ID]), list([x[:-5] for x in mgra_both if x[-5:] == '_' + second_ID]), mgra_both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cra\\AppData\\Local\\Temp\\ipykernel_20132\\3044449395.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  diff_df[f'{column}_diff'] = first_second_ID_comparison[f'{column}_{first_ID}'] - first_second_ID_comparison[f'{column}_{second_ID}']\n"
     ]
    }
   ],
   "source": [
    "cpa_diff = create_diff_temp(list([x[:-5] for x in cpa_both if x[-5:] == '_' + first_ID]),list([x[:-5] for x in cpa_both if x[-5:] == '_' + second_ID]), cpa_both) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cra\\AppData\\Local\\Temp\\ipykernel_20132\\3044449395.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  diff_df[f'{column}_diff'] = first_second_ID_comparison[f'{column}_{first_ID}'] - first_second_ID_comparison[f'{column}_{second_ID}']\n"
     ]
    }
   ],
   "source": [
    "jur_diff = create_diff_temp(list([x[:-5] for x in jur_both if x[-5:] == '_' + first_ID]), list([x[:-5] for x in jur_both if x[-5:] == '_' + second_ID]), jur_both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cra\\AppData\\Local\\Temp\\ipykernel_20132\\3044449395.py:19: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  diff_df[f'{column}_diff'] = first_second_ID_comparison[f'{column}_{first_ID}'] - first_second_ID_comparison[f'{column}_{second_ID}']\n"
     ]
    }
   ],
   "source": [
    "region_diff = create_diff_temp(list([x[:-5] for x in region_both if x[-5:] == '_' + first_ID]), list([x[:-5] for x in region_both if x[-5:] == '_' + first_ID]), region_both)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6db16e9940ad839c1e288012a4d7b04c8c55c67646ae73b178066b197eb654ea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
